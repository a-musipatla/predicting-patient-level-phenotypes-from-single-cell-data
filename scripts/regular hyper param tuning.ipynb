{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, 'dnn/')\n",
    "\n",
    "# del bnn\n",
    "import bcell_nn as bnn\n",
    "import bcell_plot\n",
    "import bcell_preprocess as bpreprocess\n",
    "# import bcell_driver\n",
    "\n",
    "# System arguments\n",
    "import argparse\n",
    "# data management\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# flow cytometry libraries\n",
    "import cytoflow as flow\n",
    "# user defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9237567583143748483\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 17236365173009617228\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 13938741275630553361\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11141855360\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 3159990129296233153\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify data files\n",
    "marrow_basal_file = '../data/B_cell_data/Marrow1_01_Basal1.fcs'\n",
    "marrow_bcr_file   = '../data/B_cell_data/Marrow1_06_BCR.fcs'\n",
    "\n",
    "# using the cytoflow package\n",
    "basal_tube = flow.Tube(file = marrow_basal_file,\n",
    "                  conditions = {'bcr' : 0.0})\n",
    "bcr_tube   = flow.Tube(file=marrow_bcr_file,\n",
    "                  conditions = {'bcr' : 1.0})\n",
    "\n",
    "import_op = flow.ImportOp(conditions = {'bcr' : 'float'},\n",
    "                          tubes = [basal_tube, bcr_tube])\n",
    "\n",
    "\n",
    "ex = import_op.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE = 0.02\n",
    "VAL = 0.2\n",
    "TEST = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_df   = bpreprocess.tube_to_df(ex)\n",
    "cyto_dataset = bpreprocess.df_to_train_tensor(cells_df, use=USE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = bpreprocess.split_dataset(cyto_dataset, VAL, TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test best shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = [\n",
    "    [20, 7],\n",
    "    [20, 16, 16, 8],\n",
    "    [20, 16, 16, 16],\n",
    "    [20, 16, 32, 16, 8],\n",
    "    [16, 32, 128, 32, 16]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(shape=None, dropout=0.1):\n",
    "\n",
    "    ###\n",
    "    # inputs:\n",
    "    #   shape: the number of nodes per each layer of neural network. First element is the input size\n",
    "    #   dropout: dropout layer will be added to the penultimate layer, dropout size\n",
    "    ###\n",
    "\n",
    "    model = None\n",
    "    if not shape:\n",
    "        # Define Sequential model with 3 layers\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(20, activation=\"relu\", name=\"layer1\"),\n",
    "                layers.Dense(7, activation=\"relu\", name=\"layer2\"),\n",
    "#                 layers.Dropout(dropout),\n",
    "                layers.Dense(1, activation='sigmoid', name=\"layer3\"),\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        model = keras.Sequential()\n",
    "        for i, x in enumerate(shape):\n",
    "            model.add(layers.Dense(x, activation='relu', name='layer%d' % (i+1)))\n",
    "        model.add(layers.Dropout(dropout, name='dropout'))\n",
    "        model.add(layers.Dense(1, activation='sigmoid', name='layer%d' % (i+2)))\n",
    "\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 1.9319 - accuracy: 0.5837 - val_loss: 0.8116 - val_accuracy: 0.5692\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 1.1515 - accuracy: 0.5775 - val_loss: 0.8809 - val_accuracy: 0.5652\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 1.0794 - accuracy: 0.5799 - val_loss: 0.8327 - val_accuracy: 0.5779\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.7147 - accuracy: 0.5799 - val_loss: 0.6833 - val_accuracy: 0.5685\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.7275 - accuracy: 0.5740 - val_loss: 0.6856 - val_accuracy: 0.5706\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6835 - accuracy: 0.5725 - val_loss: 0.6864 - val_accuracy: 0.5732\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6978 - accuracy: 0.5772 - val_loss: 0.6834 - val_accuracy: 0.5644\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6916 - accuracy: 0.5720 - val_loss: 0.6876 - val_accuracy: 0.5772\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6890 - accuracy: 0.5777 - val_loss: 0.6754 - val_accuracy: 0.5889\n",
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6950 - accuracy: 0.5737 - val_loss: 0.6814 - val_accuracy: 0.5706\n",
      "3465/3465 [==============================] - 3s 979us/step - loss: 0.6780 - accuracy: 0.5853\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 1.6684 - accuracy: 0.5690 - val_loss: 0.6826 - val_accuracy: 0.5703\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6875 - accuracy: 0.5764 - val_loss: 0.6810 - val_accuracy: 0.5962\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6955 - accuracy: 0.5703 - val_loss: 0.6825 - val_accuracy: 0.5692\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.8220 - accuracy: 0.5727 - val_loss: 0.6829 - val_accuracy: 0.5798\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6942 - accuracy: 0.5814 - val_loss: 0.6817 - val_accuracy: 0.5750\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6919 - accuracy: 0.5802 - val_loss: 0.6790 - val_accuracy: 0.5834\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6826 - accuracy: 0.5773 - val_loss: 0.6822 - val_accuracy: 0.5732\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6820 - accuracy: 0.5761 - val_loss: 0.6791 - val_accuracy: 0.5834\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6830 - accuracy: 0.5712 - val_loss: 0.6841 - val_accuracy: 0.5666\n",
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6863 - accuracy: 0.5744 - val_loss: 0.6780 - val_accuracy: 0.5911\n",
      "3465/3465 [==============================] - 3s 972us/step - loss: 0.6841 - accuracy: 0.5711\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 3.8726 - accuracy: 0.6422 - val_loss: 1.2534 - val_accuracy: 0.7207\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 1.3282 - accuracy: 0.6767 - val_loss: 1.1128 - val_accuracy: 0.6313\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 15s 1ms/step - loss: 0.7586 - accuracy: 0.6818 - val_loss: 0.6155 - val_accuracy: 0.7065\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 15s 2ms/step - loss: 0.6472 - accuracy: 0.6648 - val_loss: 0.6360 - val_accuracy: 0.6875\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6380 - accuracy: 0.6876 - val_loss: 0.6000 - val_accuracy: 0.7105\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5813 - accuracy: 0.7117 - val_loss: 0.5437 - val_accuracy: 0.7138\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 15s 2ms/step - loss: 0.5483 - accuracy: 0.7352 - val_loss: 0.5259 - val_accuracy: 0.7466\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5244 - accuracy: 0.7366 - val_loss: 0.5110 - val_accuracy: 0.7426\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 15s 2ms/step - loss: 0.5294 - accuracy: 0.7414 - val_loss: 0.5684 - val_accuracy: 0.7145\n",
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5201 - accuracy: 0.7452 - val_loss: 0.5060 - val_accuracy: 0.7510\n",
      "3465/3465 [==============================] - 3s 969us/step - loss: 0.4983 - accuracy: 0.7394\n",
      "\n",
      "\n",
      "Test score: 0.6201181014378866\n",
      "Test accuracy: 0.6319384376207987\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 1.1288 - accuracy: 0.6805 - val_loss: 0.5431 - val_accuracy: 0.7320\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5693 - accuracy: 0.7175 - val_loss: 0.5120 - val_accuracy: 0.7514\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5377 - accuracy: 0.7315 - val_loss: 0.5231 - val_accuracy: 0.7291\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5298 - accuracy: 0.7342 - val_loss: 0.4953 - val_accuracy: 0.7488\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5242 - accuracy: 0.7424 - val_loss: 0.4961 - val_accuracy: 0.7539\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 17s 2ms/step - loss: 0.5091 - accuracy: 0.7438 - val_loss: 0.5262 - val_accuracy: 0.7616\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.4967 - accuracy: 0.7578 - val_loss: 0.4903 - val_accuracy: 0.7594\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5070 - accuracy: 0.7503 - val_loss: 0.4606 - val_accuracy: 0.7813\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.4819 - accuracy: 0.7614 - val_loss: 0.4945 - val_accuracy: 0.7623\n",
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.4839 - accuracy: 0.7640 - val_loss: 0.4572 - val_accuracy: 0.7813\n",
      "3465/3465 [==============================] - 3s 947us/step - loss: 0.4856 - accuracy: 0.7639892 - accurac\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 1.0962 - accuracy: 0.6262 - val_loss: 0.9501 - val_accuracy: 0.5761\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6015 - accuracy: 0.7056 - val_loss: 0.5544 - val_accuracy: 0.7404\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5635 - accuracy: 0.7232 - val_loss: 0.5799 - val_accuracy: 0.7039\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5394 - accuracy: 0.7305 - val_loss: 0.5316 - val_accuracy: 0.7390\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5283 - accuracy: 0.7310 - val_loss: 0.5015 - val_accuracy: 0.7422\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5233 - accuracy: 0.7329 - val_loss: 0.5072 - val_accuracy: 0.7455\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5230 - accuracy: 0.7410 - val_loss: 0.5176 - val_accuracy: 0.7430\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5114 - accuracy: 0.7509 - val_loss: 0.5241 - val_accuracy: 0.7506\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5112 - accuracy: 0.7491 - val_loss: 0.4772 - val_accuracy: 0.7590\n",
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.4948 - accuracy: 0.7536 - val_loss: 0.5211 - val_accuracy: 0.7251\n",
      "3465/3465 [==============================] - 3s 950us/step - loss: 0.5046 - accuracy: 0.7400\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.8264 - accuracy: 0.5729 - val_loss: 0.6782 - val_accuracy: 0.5874\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6815 - accuracy: 0.5774 - val_loss: 0.6791 - val_accuracy: 0.5838\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6828 - accuracy: 0.5728 - val_loss: 0.6833 - val_accuracy: 0.5699\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 17s 2ms/step - loss: 0.6813 - accuracy: 0.5775 - val_loss: 0.6830 - val_accuracy: 0.5714\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6854 - accuracy: 0.5725 - val_loss: 0.6797 - val_accuracy: 0.5820\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.7012 - accuracy: 0.5749 - val_loss: 0.6793 - val_accuracy: 0.5831\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6820 - accuracy: 0.5757 - val_loss: 0.6793 - val_accuracy: 0.5842\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6803 - accuracy: 0.5818 - val_loss: 0.6884 - val_accuracy: 0.5674\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6845 - accuracy: 0.5725 - val_loss: 0.6856 - val_accuracy: 0.5626\n",
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6832 - accuracy: 0.5714 - val_loss: 0.6850 - val_accuracy: 0.5637\n",
      "3465/3465 [==============================] - 3s 979us/step - loss: 0.6806 - accuracy: 0.5792\n",
      "\n",
      "\n",
      "Test score: 0.556937058766683\n",
      "Test accuracy: 0.694372296333313\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 17s 2ms/step - loss: 1.2783 - accuracy: 0.5872 - val_loss: 0.6885 - val_accuracy: 0.5831\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 17s 2ms/step - loss: 0.6248 - accuracy: 0.6791 - val_loss: 0.6160 - val_accuracy: 0.7017\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5749 - accuracy: 0.7059 - val_loss: 0.6407 - val_accuracy: 0.6400\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5571 - accuracy: 0.7229 - val_loss: 0.5843 - val_accuracy: 0.6831\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5523 - accuracy: 0.7282 - val_loss: 0.5217 - val_accuracy: 0.7338\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5390 - accuracy: 0.7260 - val_loss: 0.5111 - val_accuracy: 0.7514\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5218 - accuracy: 0.7367 - val_loss: 0.4752 - val_accuracy: 0.7598\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5205 - accuracy: 0.7456 - val_loss: 0.5047 - val_accuracy: 0.7536\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5104 - accuracy: 0.7511 - val_loss: 0.5417 - val_accuracy: 0.7390\n",
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5029 - accuracy: 0.7527 - val_loss: 0.5414 - val_accuracy: 0.7503\n",
      "3465/3465 [==============================] - 3s 969us/step - loss: 0.5483 - accuracy: 0.7570\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10270/10270 [==============================] - 16s 2ms/step - loss: 1.3186 - accuracy: 0.6107 - val_loss: 0.6541 - val_accuracy: 0.6970\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6248 - accuracy: 0.6854 - val_loss: 0.5489 - val_accuracy: 0.7280\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 17s 2ms/step - loss: 0.5464 - accuracy: 0.7243 - val_loss: 0.5080 - val_accuracy: 0.7474\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5725 - accuracy: 0.7279 - val_loss: 0.5350 - val_accuracy: 0.7492\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5358 - accuracy: 0.7407 - val_loss: 0.5195 - val_accuracy: 0.7411\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5242 - accuracy: 0.7393 - val_loss: 0.5163 - val_accuracy: 0.7514\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5255 - accuracy: 0.7454 - val_loss: 0.5053 - val_accuracy: 0.7506\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5052 - accuracy: 0.7510 - val_loss: 0.4980 - val_accuracy: 0.7521\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5016 - accuracy: 0.7553 - val_loss: 0.5400 - val_accuracy: 0.7521\n",
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5076 - accuracy: 0.7525 - val_loss: 0.4927 - val_accuracy: 0.7536\n",
      "3465/3465 [==============================] - 3s 964us/step - loss: 0.4931 - accuracy: 0.7466\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.9012 - accuracy: 0.6000 - val_loss: 0.7021 - val_accuracy: 0.6564\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6000 - accuracy: 0.6861 - val_loss: 0.5365 - val_accuracy: 0.7379\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5486 - accuracy: 0.7228 - val_loss: 0.6367 - val_accuracy: 0.6762\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5258 - accuracy: 0.7350 - val_loss: 0.5023 - val_accuracy: 0.7558\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5250 - accuracy: 0.7415 - val_loss: 0.5160 - val_accuracy: 0.7583\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5131 - accuracy: 0.7512 - val_loss: 0.4951 - val_accuracy: 0.7641\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5051 - accuracy: 0.7605 - val_loss: 0.4641 - val_accuracy: 0.7704\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.4884 - accuracy: 0.7645 - val_loss: 0.5169 - val_accuracy: 0.7503\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.4889 - accuracy: 0.7710 - val_loss: 0.4938 - val_accuracy: 0.7820\n",
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.4647 - accuracy: 0.7775 - val_loss: 0.4741 - val_accuracy: 0.7718\n",
      "3465/3465 [==============================] - 3s 975us/step - loss: 0.4480 - accuracy: 0.7887\n",
      "\n",
      "\n",
      "Test score: 0.4964560866355896\n",
      "Test accuracy: 0.7641173601150513\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 17s 2ms/step - loss: 1.0460 - accuracy: 0.5824 - val_loss: 0.7274 - val_accuracy: 0.5776\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6934 - accuracy: 0.5713 - val_loss: 0.6840 - val_accuracy: 0.5779\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6888 - accuracy: 0.5713 - val_loss: 0.6779 - val_accuracy: 0.5874\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6847 - accuracy: 0.5736 - val_loss: 0.6863 - val_accuracy: 0.5586\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6867 - accuracy: 0.5783 - val_loss: 0.6812 - val_accuracy: 0.5772\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6823 - accuracy: 0.5759 - val_loss: 0.6847 - val_accuracy: 0.5641\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6826 - accuracy: 0.5774 - val_loss: 0.6828 - val_accuracy: 0.5725\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6817 - accuracy: 0.5768 - val_loss: 0.6815 - val_accuracy: 0.5765\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6822 - accuracy: 0.5741 - val_loss: 0.6842 - val_accuracy: 0.5696\n",
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6804 - accuracy: 0.5801 - val_loss: 0.6749 - val_accuracy: 0.5955\n",
      "3465/3465 [==============================] - 3s 926us/step - loss: 0.6824 - accuracy: 0.5763\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.9385 - accuracy: 0.6519 - val_loss: 0.5768 - val_accuracy: 0.7189\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5704 - accuracy: 0.7149 - val_loss: 0.4916 - val_accuracy: 0.7484\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 17s 2ms/step - loss: 0.5509 - accuracy: 0.7300 - val_loss: 0.5137 - val_accuracy: 0.7536\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5332 - accuracy: 0.7362 - val_loss: 0.5275 - val_accuracy: 0.7313\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5103 - accuracy: 0.7439 - val_loss: 0.5105 - val_accuracy: 0.7550\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5095 - accuracy: 0.7463 - val_loss: 0.5238 - val_accuracy: 0.7171\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5064 - accuracy: 0.7456 - val_loss: 0.5149 - val_accuracy: 0.7627\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5120 - accuracy: 0.7466 - val_loss: 0.5436 - val_accuracy: 0.7430\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.5123 - accuracy: 0.7519 - val_loss: 0.4776 - val_accuracy: 0.7652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 17s 2ms/step - loss: 0.4838 - accuracy: 0.7578 - val_loss: 0.4541 - val_accuracy: 0.7777\n",
      "3465/3465 [==============================] - 3s 962us/step - loss: 0.4633 - accuracy: 0.7677\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.7280 - accuracy: 0.5685 - val_loss: 0.6824 - val_accuracy: 0.5728\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6886 - accuracy: 0.5709 - val_loss: 0.6819 - val_accuracy: 0.5750\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6793 - accuracy: 0.5837 - val_loss: 0.6811 - val_accuracy: 0.5776\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6823 - accuracy: 0.5739 - val_loss: 0.6831 - val_accuracy: 0.5706\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6820 - accuracy: 0.5750 - val_loss: 0.6826 - val_accuracy: 0.5728\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6809 - accuracy: 0.5788 - val_loss: 0.6792 - val_accuracy: 0.5834\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6804 - accuracy: 0.5803 - val_loss: 0.6805 - val_accuracy: 0.5794\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6807 - accuracy: 0.5792 - val_loss: 0.6822 - val_accuracy: 0.5747\n",
      "3465/3465 [==============================] - 3s 935us/step - loss: 0.6836 - accuracy: 0.5697841 - accuracy: 0.\n",
      "\n",
      "\n",
      "Test score: 0.6097364525000254\n",
      "Test accuracy: 0.637902836004893\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.8726 - accuracy: 0.5616 - val_loss: 0.6818 - val_accuracy: 0.5758\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6827 - accuracy: 0.5730 - val_loss: 0.6827 - val_accuracy: 0.5721\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6821 - accuracy: 0.5746 - val_loss: 0.6853 - val_accuracy: 0.5648\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6828 - accuracy: 0.5720 - val_loss: 0.6819 - val_accuracy: 0.5761\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6820 - accuracy: 0.5748 - val_loss: 0.6844 - val_accuracy: 0.5670\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6821 - accuracy: 0.5749 - val_loss: 0.6806 - val_accuracy: 0.5794\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6804 - accuracy: 0.5800 - val_loss: 0.6838 - val_accuracy: 0.5714\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6799 - accuracy: 0.5819 - val_loss: 0.6719 - val_accuracy: 0.6050\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 17s 2ms/step - loss: 0.6813 - accuracy: 0.5776 - val_loss: 0.6812 - val_accuracy: 0.5772\n",
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6804 - accuracy: 0.5801 - val_loss: 0.6831 - val_accuracy: 0.5725\n",
      "3465/3465 [==============================] - 3s 995us/step - loss: 0.6825 - accuracy: 0.5740\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 17s 2ms/step - loss: 0.7766 - accuracy: 0.5632 - val_loss: 0.6825 - val_accuracy: 0.5728\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6830 - accuracy: 0.5743 - val_loss: 0.6805 - val_accuracy: 0.5798\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6826 - accuracy: 0.5733 - val_loss: 0.6816 - val_accuracy: 0.5761\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6824 - accuracy: 0.5736 - val_loss: 0.6851 - val_accuracy: 0.5637\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6822 - accuracy: 0.5745 - val_loss: 0.6870 - val_accuracy: 0.5568\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6832 - accuracy: 0.5708 - val_loss: 0.6838 - val_accuracy: 0.5696\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6818 - accuracy: 0.5759 - val_loss: 0.6784 - val_accuracy: 0.5863\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6814 - accuracy: 0.5772 - val_loss: 0.6867 - val_accuracy: 0.5590\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6817 - accuracy: 0.5759 - val_loss: 0.6825 - val_accuracy: 0.5728\n",
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.6831 - accuracy: 0.5714 - val_loss: 0.6807 - val_accuracy: 0.5801\n",
      "3465/3465 [==============================] - 3s 950us/step - loss: 0.6823 - accuracy: 0.5740\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 17s 2ms/step - loss: 0.8945 - accuracy: 0.5978 - val_loss: 0.6353 - val_accuracy: 0.6524\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 17s 2ms/step - loss: 0.5962 - accuracy: 0.6780 - val_loss: 0.5462 - val_accuracy: 0.7145\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 17s 2ms/step - loss: 0.5646 - accuracy: 0.7225 - val_loss: 0.5257 - val_accuracy: 0.7236\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 17s 2ms/step - loss: 0.5425 - accuracy: 0.7290 - val_loss: 0.5530 - val_accuracy: 0.7452\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 17s 2ms/step - loss: 0.5375 - accuracy: 0.7374 - val_loss: 0.5131 - val_accuracy: 0.7481\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 17s 2ms/step - loss: 0.5276 - accuracy: 0.7459 - val_loss: 0.5030 - val_accuracy: 0.7568\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 17s 2ms/step - loss: 0.5131 - accuracy: 0.7540 - val_loss: 0.5190 - val_accuracy: 0.7495\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 17s 2ms/step - loss: 0.5169 - accuracy: 0.7567 - val_loss: 0.5006 - val_accuracy: 0.7623\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 17s 2ms/step - loss: 0.5068 - accuracy: 0.7555 - val_loss: 0.4783 - val_accuracy: 0.7758\n",
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 17s 2ms/step - loss: 0.4867 - accuracy: 0.7649 - val_loss: 0.5058 - val_accuracy: 0.7725\n",
      "3465/3465 [==============================] - 3s 963us/step - loss: 0.4930 - accuracy: 0.7737986 - accuracy: 0.\n",
      "\n",
      "\n",
      "Test score: 0.6192682484785715\n",
      "Test accuracy: 0.6405964493751526\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "losses = []\n",
    "for s in shapes:\n",
    "    temp_score = 0\n",
    "    temp_acc = 0\n",
    "    N = 3\n",
    "    for _ in range(N):\n",
    "        model = define_model(shape=s, dropout=0)\n",
    "        _, history = bnn.fit_model(model, train_dataset, val_dataset, train_dataset, batch_size=128, epochs=10)\n",
    "        score, acc = model.evaluate(test_dataset)\n",
    "        temp_score += score\n",
    "        temp_acc += acc\n",
    "    print('\\n')\n",
    "    print('Test score:', temp_score/N)\n",
    "    print('Test accuracy:', temp_acc/N)\n",
    "    print('\\n')\n",
    "    \n",
    "    accs.append(temp_acc/N)\n",
    "    losses.append(temp_score/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6319384376207987,\n",
       " 0.694372296333313,\n",
       " 0.7641173601150513,\n",
       " 0.637902836004893,\n",
       " 0.6405964493751526]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accs)\n",
    "# [0.8035136461257935,\n",
    "#  0.5715441703796387,\n",
    "#  0.8144937753677368,\n",
    "#  0.8509015440940857,\n",
    "#  0.7903375029563904]\n",
    "\n",
    "# [0.6319384376207987,\n",
    "#  0.694372296333313,\n",
    "#  0.7641173601150513,\n",
    "#  0.637902836004893,\n",
    "#  0.6405964493751526]\n",
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6201181014378866,\n",
       " 0.556937058766683,\n",
       " 0.4964560866355896,\n",
       " 0.6097364525000254,\n",
       " 0.6192682484785715]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD5CAYAAADCxEVRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAvo0lEQVR4nO3deVxTZ74G8CcLErYQogJiWBRRqQrK5ta6tNZWWy1T60jE0HacOp1WtFbp6v3MnbnXXdsijtN6OzPWBSy2DB1FbafWpeLC4oICIkpYXFC2sAhBCOf+YU2NomFJeE+S3/evJifLk2PycPrm5H0FHMdxIIQQYpWErAMQQggxHyp5QgixYlTyhBBixajkCSHEilHJE0KIFaOSJ4QQKyZmHeB+2dnZrCMQQohFCg0Nbfd6XpU88OigxuTn5yMwMNDEabqPcnUO5eocytV5fM3WnVyPO0Cm4RpCCLFiVPKEEGLFqOQJIcSKUckTQogVo5InhBAr1qGza5KTk5GSkgI7OzusXLkS3t7e+m1VVVX485//DI1Gg759+2LDhg3YtWsXvv32W4hEIowYMQIff/yx2V4AIYSQRzNa8hqNBrt370ZSUhLy8vKwfv16xMfH67evXr0ay5Ytg4+Pj/66cePGYc6cORAIBFiyZAmys7O7fGokIYSQrjM6XJOTk4OIiAiIxWIEBQVBrVbrt+l0OhQVFSEhIQHz5s3Dvn37AAA+Pj4QCAQAADs7O4jF5j0d/0blbRzJqQZNjU8IIYaMtm9tbS1cXV31l+8v0qqqKhQUFGDdunXw9PTE3LlzMW7cOMhkMgDAmTNnUFVVheDg4IceNyEhAZs2bTK4LjExEfn5+Z1+EVV1d/BDdhUkvU5h9FBX43foQVqttkuvydwoV+dQrs7hay6Af9nqGltR09ACdxeYJZfRkpdKpSgoKNBfFgp/Pfh3dXWFl5cXBg4cCAAYNmwYSktLIZPJoFarsXr1avztb39r93FjY2MRGxtrcF12dnaXf/FVfFOLf6XfwsTRgRjgxZ+it8Zf15kT5eocytV5LLPV1GlReFWDK2UaXL5ai8tXNaiu00IutcfiSIVZfvFqtOSDg4OxefNm6HQ6XLx4Eb6+vvpt9vb28PDwQGVlJdzc3FBYWAgvLy/cunULcXFx2LBhA+RyeZdCd1ZogBTVTb2wZlsmPnlnIhwldj3yvIQQ0p6aOi0uX/2lzMs0+kJ3drDDIIUM/gpXTA5TYJBCBg+5Iy5evGiWHEZLXiaTITIyEtHR0RCLxVixYgVSUlKgUCgQERGB9957D4sXL0ZLSwtmzJiBPn364KOPPkJ1dTWWL18OAHjzzTcxfvx4s7yA+y34zQgsiz+Kv+4+h2XzQvXfCxBCiDndX+hXrmpQWHa30J0c7BDQTqH3ZDd16BtRpVIJpVKpv3z/0fyIESOwc+dOg9uvXLnSRPE6R9JLjPdjwvHuZ0dw4GQJpo31Y5KDEGK9Hiz0y1c1qKq9W+iDFK4YpJBhUiibQm8P72ah7C5vDxe8PXskNn59BoO9ZfBXyFhHIoRYqJp6La5crUVhmeaRhT4xRIEAb34UenusruQBYFKIAheuVGLN9ix8toTG5wkhxt0r9MtXNfox9PYKfZBCBs/e/Cz09lhlyQPAG5EjELfxKDYmn8X7qjCL+QchhJjfIwtdIoa/QoYAb8ss9PZYbcnb24nwQUw43vn0CPalq/HCkwNZRyKEMPBgoV8srkTt7Uv6Qh+kkGHiKAUGeVt+obfHakseALz6OiN29kh8knQaQ3zlGOQtYx2JEGJGmvrmX74UvVvoV65qUHnfEfoghQz+7gJMHPME+vV2srpCb49VlzwAPDWqP84XVWL1tkx89u4kODvQ+Dwh1uBeod87ZbG9Qp84SgF/b1d4yp0gFN4t9Pz8fHj1cWacvudYfckDwO9nDkdcyc/Y+PUZfPhquE389SbEmtxf6PdOX6zUNOkL3V8hw4RR/e8OudxX6MRGSr6Xfnz+MPYcK8LMp/xZRyKEPMKjCt1RIoZ/fxkGecvw1Mj+v3wpSoVujE2UPAD06+OERXNGYf2OLAz1lWOwjxvrSITYvNoGwzH0BwvdX+FKhd5NNlPyADA+yAsXxvphzbZMxL87Cc6OvVhHIsRm3F/o935g9GChPxncHwHeVOimZFMlDwC/mzEMBSU1+GzXGXz8egSNzxNiBre1OmRfvKkv9MtXNaioaYKDvRj+v/ywaHyQFwZ5y9CPCt2sbK7k7cQivKcKwzufHsF3R68gcuIg1pEIsSrXKhqwMqkIYnEJFToP2FzJA4BnbycsnjMKa7dnYqifHEN9e2Y6ZEJsQVq6Gj7uEnzy7rNU6DxgdPk/azV2RD9MHz8Aa7Zloe72HdZxCLEKTc2tOJhZivHDZFTwPGGzJQ8Ar70wDHKpPT5NOo22NloflpDuOpxdBkeJHQJ9bOfHRnxn0yVvJxbifVU4LhZXI/XIZdZxCLFoHMdhb7oa08b6QURH8bxh0yUPAO5yRyxRhmDbvnzkqatYxyHEYl24UoXrFbcxdbSv8RuTHmPzJQ8AEcM8MXOCP9Zuz0JtQzPrOIRYpLR0NZ4c6QWZiz3rKOQ+VPK/iJkeCHc3R3xC4/OEdFqlpgknLtzAC+MHsI5CHkAl/wuxSIi4eWEoLNXg20OFrOMQYlEOnCzGQC8phtB0IbxDJX+fvm4OeHduCHYeuIgLVypZxyHEIrS0tuH7kyV4YfxA+gU5D1HJPyAs0AORE/2xbkcWNPU0Pk+IMcdzrkOna8NTo/qzjkLaQSXfDtW0QHj2dsKGxGzoaHyekMdKS1dj6mhf2NuJWEch7aCSb4dIJMR7qjAUXavFNwcvsY5DCG9duarBxZJqPD/Wj3UU8ggdKvnk5GRERUVBpVKhrKzMYFtVVRUWLVqEmJgYLF26FADQ1taGP/3pT5g7dy7eeecdaLVa0yc3s96uDlg6NxRJPxQg53IF6ziE8FJauhrhgZ7w7O3EOgp5BKMlr9FosHv3buzYsQNxcXFYv369wfbVq1dj2bJl2LZtGzZs2AAAOHr0KIRCIRITEzF8+HB8++235klvZiFD3THr6QCs35GNmnrL+0NFiDnVN97BkdNX6bRJnjNa8jk5OYiIiIBYLEZQUBDUarV+m06nQ1FRERISEjBv3jzs27cPAJCVlYVJkyYBACZPnoysrCzzpO8Bc6cOQX93Z6zfQePzhNzvx4xS9JE5YOTgvqyjkMcwOtVwbW0tXF1d9Zc57teiq6qqQkFBAdatWwdPT0/MnTsX48aNM7iPi4sLamtrH3rchIQEbNq0yeC6xMRE5Ofnd+mFaLXaLt/XmMjRrvgspQSbEo9hamgf3uTqDsrVOZTLUBvHIfVwMZ4cJkNBwUXe5OoIvmYzVy6jJS+VSlFQUKC/LBT+evDv6uoKLy8vDBw4EAAwbNgwlJaWQiqVoq6uDgBQX19v8EfintjYWMTGxhpcl52djcDAwC69kPz8/C7ftyPed/HAf//fSUyMGIKRg915k6urKFfnUC5DWfk3cbu5CMoXw+HsYMebXB3B12zdyZWdnf3IbUaHa4KDg5GZmQmdTofc3Fz4+v46+ZC9vT08PDxQWVkJnU6HwsJCeHl5ITw8HEePHgVwd3w+LCysS8H5ZORgd8x+ZjA27DyN6joanye2be+xIkwO9W634Am/GC15mUyGyMhIREdHY9WqVVi6dClSUlKQkZEBAHjvvfewePFiKJVKzJgxA3369MGECRNw584dzJ07F2fPnsXLL79s9hfSE6KmDoGPpwvW7ciCTtfGOg4hTFyvbMDpglv0hauF6NDyf0qlEkqlUn/5/qP5ESNGYOfOnQa3FwqF+Mtf/mKiiPwhEgqwLDoUiz45jKQfCjBvGv/+l48Qc9t/vBhPDOgNv35S1lFIB9CPoTrJTSpB3LxQfPNTIU4X3GIdh5Aepb3Tiv9klNJRvAWhku+CoEF9ETV1CDbszEZVbRPrOIT0mCOnr8HeToixI/qxjkI6iEq+i2Y/MxgD+7ti3Y5sGp8nNoHjOKSlF+H5sQMgFlF1WAr6l+oikVCApXNDcaOyATsOPHyeMCHWJr+4GqXl9XhuDC3vZ0mo5LtB5mKPZfPC8K/Dl5GVf5N1HELMKu2YGuODvCCXSlhHIZ1AJd9NI/z7YO5zQ/FJYjYqamh8nlin6jot0nOuYzp94WpxqORN4JWnAxDg44a12zPRSuPzxAp9f7IEPp4ueGKAnHUU0klU8iYgFArwrjIEFZombN/HvzkxCOmOVl0bDpxQ0/J+FopK3kRcne3xnioM3x29goy8ctZxCDGZkxduoLmlDRNDaHk/S0Qlb0JPDOgN1bRAfJp4GreqG1nHIcQk9h5T49kIH0h6degH8oRnqORN7DeTBmGonxxrt2ehpZXG54llK75Rhzx1FaaN82MdhXQRlbyJCYUCLFGGoKpOi6/S8ljHIaRb0tLVCBniDq8+zqyjkC6ikjcDqVMvvK8KQ1p6ES4UN7COQ0iXNDS14FB2Gc1TY+Go5M1kqJ8cMdOfQPLRcpRX3WYdh5BO+ymzFG4u9ggZ6sE6CukGKnkzipzoj4GeDlizPQstrTrWcQjpsLY2DmnpakwfNwAiIZ02acmo5M1IIBDgtxM9UdfQjH/upfF5YjnOFlagUtOEKRE+rKOQbqKSNzNHexHejwnH/uNqpOdcZx2HkA5JO6bGxBAFXBx7sY5CuolKvgcM9nHD6y8Ow8avz+BGJY3PE367Wd2IzPxy+sLVSlDJ95AZTw1EcEBfrNmeiTstND5P+Gv/cTWG+srhr5CxjkJMgEq+hwgEAiyaMwoNjS34+78vsI5DSLuaW3T44VQJzTZpRajke5Czgx3ejwnDD6dK8fOZa6zjEPKQn89cg0gkxPggL9ZRiIlQyfewAG83zJ85DAm7z+J6Bf1QivDHveX9nhvjCzsxVYO1oH9JBl4YPwAhQ92xelsmmml8nvDEpdIaFF2vw7SxfqyjEBOikmdAIBAgdvZIaJt1+PI7Gp8n/LA3XY2xw/uht6sD6yjEhDpU8snJyYiKioJKpUJZWZnBNpVKpd+2ZcsWAEBLSwsWLVqEuXPnQqlU4tKlS6ZPbuGcfhmfP5hZiiOnr7KOQ2ycpr4Zx85ep9MmrZDRCaI1Gg12796NpKQk5OXlYf369YiPjze4zebNmyGX/7osWEZGBpydnbFx40ZkZWXhyy+/xNq1a02f3sL5K2R446Xh+Os3Z+GvcIXC3YV1JGKjfjhVAq++Thju35t1FGJiRo/kc3JyEBERAbFYjKCgIKjV6odus3DhQsyfPx/5+XeXvvP29kZLSwsAoK6uzuAPADH0/Fg/hAd6Ys22LGjvtLKOQ2yQTteG/cfVeGH8AFrezwoZPZKvra2Fq6ur/jLHcQbb4+PjIZfLUVhYiLi4OKSmpsLT0xONjY2YNm0aGhsbsX379oceNyEhAZs2bTK4LjExUf+HorO0Wm2X72tOHck1JUiCjam3sPafP2P2BE/e5GKBcnWOKXJdKK5HQ+MdeDk3muw18nV/AfzNZrZcnBGHDx/m1q1bp788c+bMR9521qxZXFNTE7dr1y5uzZo1HMdx3KVLl7jXX3/d2NNwHMdxWVlZHbpde/Ly8rp8X3PqaK6iaxru5ff+zR3MLDVzorssfX/1NGvO9dHmY9wX/8oxQZpf8XV/cRx/s3Un1+O60+hwTXBwMDIzM6HT6ZCbmwtfX1+D7Q0Nd8/1rqioQFNTEyQSCdra2uDm5gYAkEqlqKurM/1fJyszwMsVC34zApu/PYfSctpfpGeU3azH+SuVmE7L+1kto8M1MpkMkZGRiI6OhlgsxooVK5CSkgKFQoGwsDDExMRAIpFAp9Nh+fLlAICZM2di6dKlOHr0KJqamrBkyRKzvxBrMHW0Ly5cqcLqbVn4ZPEESOxp4WRiXmnpagQH9KUv/a1Yh1pEqVRCqVTqL99/NJ+SkvLQ7Z2cnPD555+bIJ5tEQgEeOuVYLz72RF8/q8cvBMVwjoSsWKN2hb8lFWKd+eGso5CzIh+DMUzDvZifBATjp/PXsePGaWs4xArdiirDM6OvRD+RM982U/YoJLnId9+Uvzx5RH4W0oOSm7Q+DwxPY7jkHaclvezBVTyPDUlwhdPBnth9bZMNDXT+fPEtHIuV6K8qhHP0vJ+Vo9Knsf++HIQBAIBNn977qHfJxDSHWnpajw1sj9cne1ZRyFmRiXPYxJ7MT6ICcOJ8zfwwykanyemcaumEacu3KB5amwElTzP+XhK8dasIGz5Vw7U12tZxyFW4MCJYgzylmGwjxvrKKQHUMlbgKfDfDAxRIE12zLRqG1hHYdYsJbWu8v70VG87aCStxALfjMCYpEQf/2GxudJ1x07dx0cBzwZ3J91FNJDqOQthKSXGO/HhCMjtxwHTpawjkMsVNoxNZ4b44tediLWUUgPoZK3IN4eLnh79kj8X+p5XLmqYR2HWJjCshoUltXgeVrez6ZQyVuYSSEKPB3mjTXbs2h8nnRKWroaEcM84e7myDoK6UFU8hbojcgRkPQSYWPyWRqfJx1Sd/sOjp65Rl+42iAqeQtkbyfC+zHhOH3xJvalP7xSFyEP+s+pEri7OSI4oC/rKKSHUclbqP59nRE7exS+/HcuLpdpWMchPKZr47DvRDEt72ejqOQt2FOj+uPZ0T5YvS0TDU00Pk/al51/E/W3m/FMuDfrKIQBKnkL9/uZw+HkYIeNX5+h8XnSrr3HijA51BuOEjvWUQgDVPIWrpedCB/EhONcYQX2HCtiHYfwzLWKBpwtrMB0+sLVZlHJW4F+fZywaM4o/HNPLi6V1rCOQ3hkX7oaI/z7wNdTyjoKYYRK3kqMD/LC82P9sGZbJhoa77COQ3igqbkVBzNL6SjexlHJW5HfzRgGqbM9PttF4/MEOHz6KhzsxRgzjJb3s2VU8lbETizC+6owXLhSie+OXmEdhzDEcRz2pavx/Dg/iET0Mbdl9K9vZTx7O2Fx1Ch8lZaHiyXVrOMQRnKLqnD1Vj2mjvZlHYUwRiVvhcaO8ML08QOwZlsW6m7T+Lwt2puuxpPB/eHmImEdhTBGJW+lXnthGORSe3yadBptbTQ+b0uqaptw8jwt70fu6lDJJycnIyoqCiqVCmVlZQbbVCqVftuWLVv01x8+fBivvvoqVCoVUlNTTRqaGGcnFuJ9VTguFlcj9chl1nFIDzpwogR+XlIM8aXl/QggNnYDjUaD3bt3IykpCXl5eVi/fj3i4+MNbrN582bI5XL95erqaqSkpOAf//gHRCJanIAVd7kjlihDsHJrBob6yfHEgN6sIxEza2ltw/cni6GaFkjz1BAAHTiSz8nJQUREBMRiMYKCgqBWPzzr4cKFCzF//nzk5+cDAI4cOQJHR0e88cYbePPNN3H9+nXTJycdEjHMEzMn+GPt9izUNjSzjkPM7MT562jVtWFCiIJ1FMITAs7ICdV79uzBjRs3sGDBAgDAjBkzsGfPHv326upqyOVyFBYWIi4uDqmpqfjiiy9w/Phx/P3vf0dGRgaSk5Px2WefGTxuQkICNm3aZHBdYmIiHB27tqCBVquFRMK/L5n4kEvXxuHzvWWQ9BLi9ef6QygQ8CJXeyhX5zyYa/OeMvi6S/DCaLZTCvN1fwH8zdadXI2NjQgNDW13m9HhGqlUioKCAv1lodDw4P/eME1AQADEYjG0Wi2kUinGjBkDsViMcePGYdWqVQ89bmxsLGJjYw2uy87ORmBgoPFX1I78/Pwu39ec+JLrT14DsPiTQ8i7IcbsZwbzJteDKFfn3J+r6FotSm5dwsfzx8OztxNvcvENX7N1J1d2dvYjtxkdrgkODkZmZiZ0Oh1yc3Ph62t43m1DQwMAoKKiAk1NTZBIJIiIiEBeXp4+eP/+tDI8a33dHPDu3FDsPHARF65Uso5DzCAtXY2wQA/mBU/4xeiRvEwmQ2RkJKKjoyEWi7FixQqkpKRAoVAgLCwMMTExkEgk0Ol0WL58OQDA398fgYGBmDdvHtra2vCXv/zF7C+EGBcW6IHIif5YtyMLC2fQH15r0tB4B4dPX8VHr4WzjkJ4xmjJA4BSqYRSqdRfvv9oPiUlpd37vPXWW3jrrbe6GY+YmmpaIPKLq5F0uBwhI4dDJKQzMKzBj5ml6O0qwajB7qyjEJ6hH0PZGJFIiPdUYbhR1YzE7y+yjkNMoK2Nw770YkwfNwBC+qNNHkAlb4N6uzog+pl++PanQpy8cIN1HNJNpwtuobpeiym0vB9pB5W8jfLv54jXXhyGTxJP4+qtetZxSDekpasxKUQBZ8derKMQHqKSt2EvTRiIsEAPrNyaiabmVtZxSBdU1d1B9sWbNE8NeSQqeRsmEAiw6LcjIRQA8bQQuEU6kV+LJwb0xgAvV9ZRCE9Ryds4ib0YH70WgTMFt5B6hBYasSTaO63IvFSLF8bRUTx5NCp5Aq++zlg6NxRfpeUh53IF6zikg46euQaxSIAxI/qxjkJ4jEqeALg7kdkrzwRg7fYsVNQ0sY5DjOA4DmnH1Bg9xBV2YvoYk0ejdwfRU04dikEKGVZvy0BLq451HPIYF4trUFJeh9FDZayjEJ6jkid6IqEAS6NDUdtwB1/86zzrOOQx0tLVGBfkBVenDv1ondgwKnliwMWxFz5+PQKHsq/ih1MlrOOQdtTUaZGec41OmyQdQiVPHjLAyxULZwfj85QcXCqtYR2HPOD7UyVQuLvgiQFy4zcmNo9KnrRrcqg3nhvji1VfZdKKUjzSqmvDgRPFeGH8AFrej3QIlTx5pN/NGI6+Mges25EFna6NdRwC4NSFcmibWzGJlvcjHUQlTx7JTizEB6+Go7S8Htv357OOQ3D3C9cpEb6Q2NMXrqRjqOTJY8mlErwfE47vjl5Beg4tyM5SyY06XCiqxPRxfqyjEAtCJU+MGjawN343Yzjid51G2U2asZKVtONqjBriDq++zqyjEAtCJU865MUnB2D08H5Y8c8MNGpbWMexObebWnAoq4xOmySdRiVPOkQgEODtV4LRy06Iz3bRjJU97WBWKVyd7RE61IN1FGJhqORJh0l63Z2xMudyJb75qZB1HJtxd3k/NaaP86M1eUmnUcmTTvHs7YRl0aHYeeAizhTcYh3HJpwrrEBFTROmRPiyjkIsEJU86bSwQA9ETR2CdTuycbO6kXUcq5eWrsbEEAWkTrS8H+k8KnnSJb99ZjAC/eRY9VUGmltoxkpzuVXdiMy8ckynL1xJF1HJky4RCgVYMjcEjdpW/O3bc/RFrJnsP1GMwT5uGKSQsY5CLFSHSj45ORlRUVFQqVQoKysz2KZSqfTbtmzZYrDtu+++w6hRo0yXlvCKs4MdPn4tAsfOXceBE8Ws41idOy06fH+yhE6bJN1i9LfRGo0Gu3fvRlJSEvLy8rB+/XrEx8cb3Gbz5s2Qyw1nxGtpacGBAwfQrx8tTWbNfPtJsei3I/Fp0hkM6O+Kob40M6Kp/Hz2GkRCAcYHe7GOQiyY0SP5nJwcREREQCwWIygoCGq1+qHbLFy4EPPnz0d+/q/zm3z99dd4+eWXIRTSiJC1mzBKgRfGD8CqrZmoqdeyjmM10tLVmDrGF3ZiEesoxIIZPZKvra2Fq6ur/vKDY6/x8fGQy+UoLCxEXFwcUlNT0djYiJ9//hlffPHFQ0f99yQkJGDTpk0G1yUmJhr8oegMrVbb5fuak63kGjNIiPOXBPjvz4/ijemKLp/PbSv7y5jSW024clWD2ePdHvu8tL86j6/ZzJXLaMlLpVIUFBToLz94ZH5vmCYgIABisRharRZbt25FdHT0Yx83NjYWsbGxBtdlZ2cjMDCww+Hvl5+f3+X7mpMt5fpvn4FY8ukRnLzcht+/NJw3uUyhp3MdOHsaY0b0w9jwoMfejvZX5/E1W3dyZWdnP3Kb0bGU4OBgZGZmQqfTITc3F76+hj/IaGhoAABUVFSgqakJEokERUVF+OqrrzB//nxcu3YNH374YZeCE8vi5iLBB6+GIy1djaNnrrKOY7FqG5px9Awt70dMw+iRvEwmQ2RkJKKjoyEWi7FixQqkpKRAoVAgLCwMMTExkEgk0Ol0WL58OQBg/fr1+vu/+OKLWLVqlfleAeGVob5yLIgcjo3JZ+HjKYVfPynrSBbnh1Ml6NfHCSP8+7COQqxAh1YeUCqVUCqV+sv3H82npKQ89r579+7tYjRiqZ4f64dLpRqs3JqBT96ZCGcHO9aRLIZO14b9J4oxa3IALe9HTIJOfSEmJxAI8OasIDhKxPg08TTa2uiHUh2VkXcTDY0tmBxKy/sR06CSJ2ZhbyfCR69GIL+4GskHL7GOYzH2pavxTLg3HCX0fz/ENKjkidm4yx0RNy8Uu34oQFb+TdZxeK/sZj3OXa7A9HH0hSsxHSp5Ylajhrgj+vmhWL8zG+VVt1nH4bV9x9UIHtQX3h4urKMQK0IlT8zulacDEDSoD1ZuzYD2TivrOLzUqG3Bwcwymm2SmByVPDE7gUCAd6JG4U5LG/76Dc1Y2Z7Dp6/C2dEOEU/Q8n7EtKjkSY9wlNjh49cjcOrCDaSlPzz/kS3jOA57j6kxbawfRCL6SBLToncU6THeHi5YHBWCv//7AnKLqljH4Y3zVypxo/I2po6m5f2I6VHJkx41PsgLL03wx5ptmaiuoxkrgbuzTU4Y1R+uzvasoxArRCVPepxqWiB8PF2w+qtMtLS2sY7DVKWmCScvlNM8NcRsqORJjxOJhIibF4YKTRP+secC6zhMHThRDP/+rhjs48Y6CrFSVPKECVdne3z0Wji+P1mCQ9llxu9ghVpaaXk/Yn5U8oSZAG83vPlyEDbtPoeia7Ws4/S49Jwb0LVxeGpkf9ZRiBWjkidMTR3ti8mhCqzcmoH6xjus4/SotGNFmDraB73saHk/Yj5U8oS5P/xmBFyde2H9zmybmbHy8lUNLpXWYBrNU0PMjEqeMGcnFuGDmAhcuarBf87Yxvnz+9LVCH/CEx5yR9ZRiJWjkie80NfNAe+pwnDobDUycstZxzGrutt3cOT0VfrClfQIKnnCG0GD+mJaeB9sSMzG9YoG1nHM5seMUvR1c0RwQF/WUYgNoJInvDJhhBtChrhj5dYMNDVb34yVujYO+46rMX28H4RCWt6PmB+VPOEVgUCARXNGoY0DEpLPWt2Mlacv3kRtQzOeCfNhHYXYCCp5wjsO9mJ8/HoEsi/exHdHi1jHMam96WpMDvWGEy1uTnoIlTzhpf59nbFEGYKte3Nx/nIl6zgmcb2iAWcKbtEXrqRHUckT3hozvB9mPR2AtduzUKlpYh2n2/YdL8bwgX3g20/KOgqxIVTyhNfmPjcUA/u7/jJjpY51nC7TNrfixwyap4b0vA6VfHJyMqKioqBSqVBWZjiZlEql0m/bsmULAODHH3/E7NmzER0djXfffRctLS2mT05sgkgowLJ5oahpaMb/pVrujJVHzlyFxF6M0cM9WUchNsZoyWs0GuzevRs7duxAXFwc1q9f/9BtNm/ejO3bt2PBggUAgMDAQCQmJmLnzp3w8vLC/v37TZ+c2AwXx1746NVwHMwsxY8ZJazjdNq95f2eH+sHMS3vR3qY0XdcTk4OIiIiIBaLERQUBLX64fU5Fy5ciPnz5yM/Px8A0L9/f9jZ3T17wM7ODmKx2MSxia3xV8jw9uxgbP42B5fLNKzjdEqeuhpXb9XjOVrejzAg4IyciLxnzx7cuHFDf5Q+Y8YM7NmzR7+9uroacrkchYWFiIuLQ2pqqn5baWkpli5dip07d6JXr14Gj5uQkIBNmzYZXJeYmAhHx67N5aHVaiGRSLp0X3OiXJ1jLFfq8ZvIL72NRZG+cJL03OyN3dlfO3+6AYEAmDu5n4lTWe6/I0t8zdadXI2NjQgNDW1/I2fE4cOHuXXr1ukvz5w585G3nTVrFtfU1MRxHMdVVlZyv/3tbzm1Wm3sKfSysrI6fNsH5eXldfm+5kS5OsdYrjstOi5u41Fu+d/SuVZdWw+l6vr+qqpt4l5a9h2XV1Rl4kR3Weq/I0t8zdadXI/rTqPDNcHBwcjMzIROp0Nubi58fQ3/l7Oh4e4cIxUVFWhqaoJEIsHt27cRGxuLDz/8EH5+fl36y0RIe+zEQrwfE4bi8jrsPJDPOo5R358ohm8/KYb60fJ+hA2jg+UymQyRkZGIjo6GWCzGihUrkJKSAoVCgbCwMMTExEAikUCn02H58uUAgK1bt6KkpAQbNmwAAMyaNQuRkZFmfSHEdvR2dcAHMeFY/nk6ArxlGDvCi3WkdrXq2nDgZDGinw+EQEDz1BA2OvSNqFKphFKp1F++/2g+JSXlodu//fbbePvtt00Qj5D2DRvYG6/PGIZPk85A4e4Cbw8X1pEecuL8DdxpacOEUbS8H2GHzuciFmvGkwMR8YQnVm7NQKOWf7/FSEtXY0qEDyS96Owywg6VPLFYAoEAC2cHQywSIv7rM7yasVJ9vRZ56ipMp+X9CGNU8sSiSezF+Oi1CJwrrETKocus4+ilpasROtQD/fo4sY5CbByVPLF4/fo4YVl0KLbvz8e5SxWs46ChqQWHaXk/whNU8sQqhAV6YM6UwVi7Iwu3ahqZZjmYWQq5iwQhQ9yZ5iAEoJInVmTOs0MwxNcNq77KxJ0WNjNWtrVxSEun5f0If1DJE6shFArw7txQ3G5swecpOUwynL1UgapaLaaE0/J+hB+o5IlVcXaww4evhePo2Wv4/mRxjz//3vQiTApRwNmxl/EbE9IDqOSJ1Rng5YrY2SPxecp5XCqt6bHnLa+6jaz8m/SFK+EVKnlilSaGKDB9vB9Wbc2Apr65R55z//FiBPrJMbC/a488HyEdQSVPrNbrLw6DR28nrN2eBZ2uzazP1dyiw39oeT/CQ1TyxGqJRUK8rwrDtYoGfLXPvDNW/nzmKsQiIW8nSyO2i0qeWDU3qQQfvhqOPT9fwc9nr5nlOTiOw950NZ4b4wc7MX2kCL/QO5JYvaF+crwROQIbvz6DkvI6kz9+QWkNiq/X4fmxtLwf4R8qeWITpo31w7ggL6z8ZwZuN5l2xsq0Y2qMGdEPvV0dTPq4hJgClTyxCQKBAG+9EgyJvRifJp1GW5tpZqysqdfi2LnreJG+cCU8RSVPbIa9nQgfvhqOPHUVdv90ySSP+cOpEijcnTFsYG+TPB4hpkYlT2yKZ28nLJsXhqTvC3D64q1uPZZO14YDx4sxffwAWt6P8BaVPLE5IUPcMfe5oVi3IwvlVbe7/DincsvR1NyKSSEKE6YjxLSo5IlNeuXpAAwb2BurtmaiuYszVqalq/FMuA8c7Gl5P8JfVPLEJgmFAixRhqC5pRWbvznX6aUDS8vrcP5KJabTF66E56jkic1ycrDDR69F4HjOdew7Xtyp+6alqzFqsDv693U2TzhCTIRKntg0H08pFkeNwpffnUe+urpD92nUtuBQdhnNU0MsApU8sXlPBvfHjKf8sXpbBmrqtEZv/1NWGVyc7BEa6NED6Qjpng6VfHJyMqKioqBSqVBWVmawTaVS6bdt2bJFf31CQgKUSiV+//vfo7q6Y0dIhLDy6vRAKNxdsGZ7FlofM2Mlx/2yvN9YP4hoeT9iAYyWvEajwe7du7Fjxw7ExcVh/fr1D91m8+bN2L59OxYsWAAAKCwsxPnz55GUlIRZs2bhyy+/NH1yQkxIJBIibl4Yblbdxj/35D7ydjmFlbhV3YhnR9M8NcQyGC35nJwcREREQCwWIygoCGq1+qHbLFy4EPPnz0d+/t3pXLOysjBp0iQAwOTJk5GdnW3a1ISYgczFHh++FoF9x4tx+PTVdm+zN70IT43qD6kTLe9HLIPRE3xra2vh6vrrSjcPnmoWHx8PuVyOwsJCxMXFITU1FbW1tfD29gYASCQSNDY2PvS4CQkJ2LRpk8F1iYmJ+j8UnaXVart8X3OiXJ3Dh1wvje2DjbtOo62xEv162+tzHc/MwanccsS+5MM84z182F/t4WsugL/ZzJXLaMlLpVIUFBToLwuFhgf/crkcABAQEACxWAytVgupVIq6urtTujY3N8PR0fGhx42NjUVsbKzBddnZ2QgMDOz8qwCQn5/f5fuaE+XqHD7kCgwE6lvOYtfRSnzyzgQ4O/ZCfn4+zqs5DPZxw7NPjWKa73582F/t4WsugL/ZupPrcaMlRodrgoODkZmZCZ1Oh9zcXPj6Go5FNjQ0AAAqKirQ1NQEiUSC8PBwHD16FABw5MgRhISEdCk4Iaz84Tcj4ORohw2Jd2esbGltw/cnaXk/YnmMHsnLZDJERkYiOjoaYrEYK1asQEpKChQKBcLCwhATEwOJRAKdTofly5cDuHtUP3ToUCiVSjg5OWHt2rVmfyGEmFKvX2asXPLpEXz9nwLomhsgEABPBtPyfsSydGjSDaVSCaVSqb98/9F8SkpKu/dZvHgxFi9e3M14hLDj7uaI91Rh+NOWE3CWiDB17ADYiUWsYxHSKfRjKEIeIzigL2KmB6JB24rnx/qxjkNIp9H0eYQY8ZtJg+DtqoW728MnEBDCd3QkT4gRAoEAzg50PEQsE5U8IYRYMSp5QgixYlTyhBBixajkCSHEilHJE0KIFaOSJ4QQK0YlTwghVoxKnhBCrJiAe3CCeIZocRFCCOma0NDQdq/nVcl3x5AhQwzmvecLytU5lKtzKFfn8TWbuXLRcA0hhFgxKnlCCLFiVPKEEGLFrKbkFy5cyDpCuyhX51CuzqFcncfXbObKZTVfvBJCCHmY1RzJE0IIeZhFlnxycjKioqKgUqlQVlZmsC0nJwdRUVGYM2cODh06xJtcKpVKv23Lli09lqmlpQVRUVEICwvDgQMHHtp+6NAhzJkzB1FRUcjJyeFNrilTpkClUkGlUj1yHWFzOHPmDObMmYN58+ZhwYIFqKurM9jOan8Zy8Vqf1VWViIqKgrz5s2DUqnEpUuXDLaz+jway8Xq83hPVlYWhgwZgurqaoPrzfL+4ixMTU0N98orr3AtLS3cuXPnuEWLFhlsj4qK4srLy7mGhgbupZde4lpbW3mRa968eVxVVVWPZLlfW1sbd/PmTW7jxo3c/v37Dba1trZyL730EldfX8+Vl5dzUVFRvMjFcRz3wgsv9FiW+5WXl3ONjY0cx3FcYmIit3nzZv02lvvrcbk4jt3+am1t5XQ6HcdxHHfy5Elu6dKlBttZfR6N5WL1ebxn4cKF3Msvv2yQwVzvL4s7ks/JyUFERATEYjGCgoKgVqv125qbm6HT6eDh4QEnJyf4+fmhuLiYea57Fi5ciPnz5yM/P79HMgF3l65zd3dvd1txcTH8/Pzg7OwMDw8PtLa2orm5mXku4O6Rvkqlwh//+MeH/q/InDw8PODg4AAAsLOzg0gk0m9jub8elwtgt79EIhGEwrs1Ul9fj6FDh+q3sfw8Pi7XPSw+j8Ddo/XQ0FA4OhquGWyu95fFLVxZW1sLV1dX/WXuvu+NNRoNXFxc9JelUilqa2uZ5wKA+Ph4yOVyFBYWIi4uDqmpqT2S63Fqa2shlUr1l6VSKTQaDTw8PBimuispKQlyuRwnTpzAn//8Z3z55Zc9+vw1NTVITEw0eF4+7K/2cgFs99fly5exfPly3LhxAwkJCfrrWX4eH5cLYPd5bGtrQ2JiIjZt2oSDBw8abDPX+8vijuSlUqnBeOS9v9YA4Orqivr6ev3l+vp6g+JllQsA5HI5ACAgIABisRharbZHcj1Oe/tLJpOxC3Sfe/tr7NixKC8v79HnbmpqwuLFi7F8+XJ9DoD9/npULoDt/ho0aBB27dqFL774Av/zP/+jv57l5/FxuQB2n8c9e/bg6aefhr29/UPbzPX+sriSDw4ORmZmJnQ6HXJzc+Hr66vfJpFIIBKJcOvWLTQ2NqKkpMRgO6tcANDQ0AAAqKioQFNTEyQSSY/kehxfX18UFxejsbERFRUVEIlE7b75etqdO3f0/5t66dKlHi3S1tZWLFmyBCqVCiEhIQbbWO6vx+Viub/u3Lmj/28XFxeD9zXLz+PjcgHsPo+XLl3C999/j/nz56OgoADLli3TbzPX+8siz5NPSkrCd999B7FYjBUrViA7OxsKhQIRERE4d+4cVq1aBY7jsGDBAjzzzDPMc4WFheGVV16BRCKBTqfDO++8g7Fjx/ZYrsWLF+PChQtwdHTEU089BZlMhilTpmDgwIE4ePAgtmzZAoFAgA8//BDBwcHMczk5OeEPf/gDnJycAAD/9V//1e6Yqjmkpqbif//3fxEYGAgAmDhxItra2pjvr8flYrm/zpw5gw0bNkAgEAAAPvjgAxQUFDD/PD4uF+vP4z0qlQrx8fH45ptvzPr+ssiSJ4QQ0jEWN1xDCCGk46jkCSHEilHJE0KIFaOSJ4QQK0YlTwghVoxKnhBCrBiVPCGEWDEqeUIIsWL/D+asCTerLqDsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "losses\n",
    "# [0.4393937885761261,\n",
    "#  0.6832538843154907,\n",
    "#  0.41677165031433105,\n",
    "#  0.352311909198761,\n",
    "#  0.46169131994247437]\n",
    "\n",
    "# [0.6201181014378866,\n",
    "#  0.556937058766683,\n",
    "#  0.4964560866355896,\n",
    "#  0.6097364525000254,\n",
    "#  0.6192682484785715]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test different dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropouts = np.linspace(0.0, 0.5, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 35s 3ms/step - loss: 0.9919 - accuracy: 0.6345 - val_loss: 0.6048 - val_accuracy: 0.7083\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.5774 - accuracy: 0.7115 - val_loss: 0.5270 - val_accuracy: 0.7411\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.5508 - accuracy: 0.7258 - val_loss: 0.5410 - val_accuracy: 0.7196\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.5494 - accuracy: 0.7288 - val_loss: 0.4907 - val_accuracy: 0.7470\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.5270 - accuracy: 0.7442 - val_loss: 0.5078 - val_accuracy: 0.7517\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.5253 - accuracy: 0.7469 - val_loss: 0.5227 - val_accuracy: 0.7536\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 35s 3ms/step - loss: 0.5105 - accuracy: 0.7577 - val_loss: 0.5051 - val_accuracy: 0.7484\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.5099 - accuracy: 0.7517 - val_loss: 0.5015 - val_accuracy: 0.7623\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.5033 - accuracy: 0.7545 - val_loss: 0.4969 - val_accuracy: 0.7568\n",
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.4975 - accuracy: 0.7570 - val_loss: 0.4653 - val_accuracy: 0.7828\n",
      "3465/3465 [==============================] - 7s 2ms/step - loss: 0.4556 - accuracy: 0.7841\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6951 - accuracy: 0.6442 - val_loss: 0.5516 - val_accuracy: 0.7196\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.5621 - accuracy: 0.7166 - val_loss: 0.5473 - val_accuracy: 0.7357\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.5425 - accuracy: 0.7274 - val_loss: 0.5171 - val_accuracy: 0.7532\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.5306 - accuracy: 0.7317 - val_loss: 0.5094 - val_accuracy: 0.7558\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.5050 - accuracy: 0.7452 - val_loss: 0.4899 - val_accuracy: 0.7547\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.5080 - accuracy: 0.7529 - val_loss: 0.4867 - val_accuracy: 0.7725\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.5068 - accuracy: 0.7582 - val_loss: 0.4969 - val_accuracy: 0.7514\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.4990 - accuracy: 0.7585 - val_loss: 0.4542 - val_accuracy: 0.7806\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.4858 - accuracy: 0.7722 - val_loss: 0.4656 - val_accuracy: 0.7766\n",
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.4741 - accuracy: 0.7719 - val_loss: 0.4630 - val_accuracy: 0.7835\n",
      "3465/3465 [==============================] - 7s 2ms/step - loss: 0.4436 - accuracy: 0.7911\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.7040 - accuracy: 0.5632 - val_loss: 0.6855 - val_accuracy: 0.5619\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6835 - accuracy: 0.5709 - val_loss: 0.6848 - val_accuracy: 0.5648\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6824 - accuracy: 0.5740 - val_loss: 0.6848 - val_accuracy: 0.5648\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6844 - accuracy: 0.5668 - val_loss: 0.6841 - val_accuracy: 0.5674\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6828 - accuracy: 0.5724 - val_loss: 0.6882 - val_accuracy: 0.5531\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6825 - accuracy: 0.5731 - val_loss: 0.6794 - val_accuracy: 0.5827\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6821 - accuracy: 0.5740 - val_loss: 0.6787 - val_accuracy: 0.5849\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6830 - accuracy: 0.5719 - val_loss: 0.6806 - val_accuracy: 0.5790\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6831 - accuracy: 0.5714 - val_loss: 0.6807 - val_accuracy: 0.5787\n",
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6854 - accuracy: 0.5628 - val_loss: 0.6845 - val_accuracy: 0.5655\n",
      "3465/3465 [==============================] - 7s 2ms/step - loss: 0.6835 - accuracy: 0.5697\n",
      "\n",
      "\n",
      "Test score: 0.527546226978302\n",
      "Test accuracy: 0.7149591247240702\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.7402 - accuracy: 0.6174 - val_loss: 0.5848 - val_accuracy: 0.6846\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.5832 - accuracy: 0.6951 - val_loss: 0.5555 - val_accuracy: 0.7021\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.5529 - accuracy: 0.7279 - val_loss: 0.5221 - val_accuracy: 0.7568\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.5362 - accuracy: 0.7352 - val_loss: 0.4987 - val_accuracy: 0.7444\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.5223 - accuracy: 0.7408 - val_loss: 0.5233 - val_accuracy: 0.7225\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.5183 - accuracy: 0.7458 - val_loss: 0.5374 - val_accuracy: 0.7539\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.5095 - accuracy: 0.7503 - val_loss: 0.4925 - val_accuracy: 0.7561\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.5038 - accuracy: 0.7566 - val_loss: 0.4837 - val_accuracy: 0.7598\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.5015 - accuracy: 0.7528 - val_loss: 0.4742 - val_accuracy: 0.7788\n",
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.4940 - accuracy: 0.7642 - val_loss: 0.4469 - val_accuracy: 0.7747\n",
      "3465/3465 [==============================] - 7s 2ms/step - loss: 0.4797 - accuracy: 0.7573\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 35s 3ms/step - loss: 0.7362 - accuracy: 0.5816 - val_loss: 0.6433 - val_accuracy: 0.6616\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6240 - accuracy: 0.6291 - val_loss: 0.5405 - val_accuracy: 0.7338\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.5598 - accuracy: 0.7079 - val_loss: 0.5269 - val_accuracy: 0.7375\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.5590 - accuracy: 0.7127 - val_loss: 0.5328 - val_accuracy: 0.7492\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.5402 - accuracy: 0.7271 - val_loss: 0.5005 - val_accuracy: 0.7444\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.5264 - accuracy: 0.7386 - val_loss: 0.5233 - val_accuracy: 0.7375\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.5299 - accuracy: 0.7381 - val_loss: 0.5241 - val_accuracy: 0.7393\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.5259 - accuracy: 0.7415 - val_loss: 0.4946 - val_accuracy: 0.7565\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.5112 - accuracy: 0.7478 - val_loss: 0.4931 - val_accuracy: 0.7517\n",
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.5100 - accuracy: 0.7537 - val_loss: 0.4617 - val_accuracy: 0.7747\n",
      "3465/3465 [==============================] - 7s 2ms/step - loss: 0.4795 - accuracy: 0.7680\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 35s 3ms/step - loss: 0.7122 - accuracy: 0.5685 - val_loss: 0.6825 - val_accuracy: 0.5728\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6840 - accuracy: 0.5712 - val_loss: 0.6856 - val_accuracy: 0.5622\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6844 - accuracy: 0.5698 - val_loss: 0.6868 - val_accuracy: 0.5568\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6827 - accuracy: 0.5727 - val_loss: 0.6836 - val_accuracy: 0.5692\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6839 - accuracy: 0.5685 - val_loss: 0.6852 - val_accuracy: 0.5641\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6821 - accuracy: 0.5744 - val_loss: 0.6868 - val_accuracy: 0.5586\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6841 - accuracy: 0.5676 - val_loss: 0.6849 - val_accuracy: 0.5641\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6830 - accuracy: 0.5719 - val_loss: 0.6845 - val_accuracy: 0.5659\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6823 - accuracy: 0.5743 - val_loss: 0.6792 - val_accuracy: 0.5845\n",
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 35s 3ms/step - loss: 0.6837 - accuracy: 0.5692 - val_loss: 0.6853 - val_accuracy: 0.5630\n",
      "3465/3465 [==============================] - 7s 2ms/step - loss: 0.6856 - accuracy: 0.5619\n",
      "\n",
      "\n",
      "Test score: 0.5482690930366516\n",
      "Test accuracy: 0.6957191030184428\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.7823 - accuracy: 0.5748 - val_loss: 0.6796 - val_accuracy: 0.5842\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.7177 - accuracy: 0.5686 - val_loss: 0.8140 - val_accuracy: 0.5659\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.7043 - accuracy: 0.5664 - val_loss: 0.6841 - val_accuracy: 0.5670\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6927 - accuracy: 0.5669 - val_loss: 0.6830 - val_accuracy: 0.5699\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6840 - accuracy: 0.5699 - val_loss: 0.6834 - val_accuracy: 0.5688\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6833 - accuracy: 0.5711 - val_loss: 0.6814 - val_accuracy: 0.5758\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6810 - accuracy: 0.5781 - val_loss: 0.6817 - val_accuracy: 0.5754\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6971 - accuracy: 0.5683 - val_loss: 0.6840 - val_accuracy: 0.5790\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6857 - accuracy: 0.5666 - val_loss: 0.6815 - val_accuracy: 0.5758\n",
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6820 - accuracy: 0.5745 - val_loss: 0.6840 - val_accuracy: 0.5681\n",
      "3465/3465 [==============================] - 7s 2ms/step - loss: 0.6816 - accuracy: 0.5758\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.7669 - accuracy: 0.5672 - val_loss: 0.6820 - val_accuracy: 0.5725\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6926 - accuracy: 0.5653 - val_loss: 0.6840 - val_accuracy: 0.5659\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6962 - accuracy: 0.5709 - val_loss: 0.6945 - val_accuracy: 0.5798\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6953 - accuracy: 0.5745 - val_loss: 0.6817 - val_accuracy: 0.5758\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6826 - accuracy: 0.5716 - val_loss: 0.6822 - val_accuracy: 0.5732\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6830 - accuracy: 0.5728 - val_loss: 0.7037 - val_accuracy: 0.5838\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6937 - accuracy: 0.5715 - val_loss: 0.6797 - val_accuracy: 0.5612\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6897 - accuracy: 0.5681 - val_loss: 0.6827 - val_accuracy: 0.5703\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6835 - accuracy: 0.5710 - val_loss: 0.6831 - val_accuracy: 0.5637\n",
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6860 - accuracy: 0.5680 - val_loss: 0.6827 - val_accuracy: 0.5666\n",
      "3465/3465 [==============================] - 7s 2ms/step - loss: 0.6818 - accuracy: 0.5723\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 1.0728 - accuracy: 0.5608 - val_loss: 0.6867 - val_accuracy: 0.5579\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6867 - accuracy: 0.5741 - val_loss: 0.7006 - val_accuracy: 0.5783\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6888 - accuracy: 0.5723 - val_loss: 0.6788 - val_accuracy: 0.5849\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6831 - accuracy: 0.5709 - val_loss: 0.6821 - val_accuracy: 0.5747\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6836 - accuracy: 0.5696 - val_loss: 0.6879 - val_accuracy: 0.5535\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6806 - accuracy: 0.5794 - val_loss: 0.6853 - val_accuracy: 0.5622\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6834 - accuracy: 0.5703 - val_loss: 0.6819 - val_accuracy: 0.5758\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6838 - accuracy: 0.5689 - val_loss: 0.6842 - val_accuracy: 0.5670\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6830 - accuracy: 0.5714 - val_loss: 0.6832 - val_accuracy: 0.5699\n",
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6823 - accuracy: 0.5740 - val_loss: 0.6804 - val_accuracy: 0.5801\n",
      "3465/3465 [==============================] - 7s 2ms/step - loss: 0.6831 - accuracy: 0.5706\n",
      "\n",
      "\n",
      "Test score: 0.6822094718615214\n",
      "Test accuracy: 0.5728715658187866\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.8768 - accuracy: 0.5653 - val_loss: 0.6838 - val_accuracy: 0.5685\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6837 - accuracy: 0.5695 - val_loss: 0.6865 - val_accuracy: 0.5582\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6826 - accuracy: 0.5733 - val_loss: 0.6826 - val_accuracy: 0.5725\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6828 - accuracy: 0.5720 - val_loss: 0.6826 - val_accuracy: 0.5739\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6820 - accuracy: 0.5753 - val_loss: 0.6810 - val_accuracy: 0.5779\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6844 - accuracy: 0.5661 - val_loss: 0.6841 - val_accuracy: 0.5696\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6822 - accuracy: 0.5751 - val_loss: 0.6859 - val_accuracy: 0.5612\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6833 - accuracy: 0.5706 - val_loss: 0.6779 - val_accuracy: 0.5904\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6826 - val_accuracy: 0.5725\n",
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6836 - accuracy: 0.5695 - val_loss: 0.6849 - val_accuracy: 0.5644\n",
      "3465/3465 [==============================] - 7s 2ms/step - loss: 0.6841 - accuracy: 0.5671\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 1.0408 - accuracy: 0.5675 - val_loss: 0.6824 - val_accuracy: 0.5732\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6941 - accuracy: 0.5623 - val_loss: 0.6849 - val_accuracy: 0.5655\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 35s 3ms/step - loss: 0.6848 - accuracy: 0.5655 - val_loss: 0.6868 - val_accuracy: 0.5564\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6841 - accuracy: 0.5680 - val_loss: 0.6810 - val_accuracy: 0.5787\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 51s 5ms/step - loss: 0.6833 - accuracy: 0.5709 - val_loss: 0.6846 - val_accuracy: 0.5652\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6829 - accuracy: 0.5723 - val_loss: 0.6841 - val_accuracy: 0.5674\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6817 - accuracy: 0.5761 - val_loss: 0.6835 - val_accuracy: 0.5696\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6841 - accuracy: 0.5679 - val_loss: 0.6832 - val_accuracy: 0.5706\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6840 - accuracy: 0.5680 - val_loss: 0.6883 - val_accuracy: 0.5553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6841 - accuracy: 0.5678 - val_loss: 0.6856 - val_accuracy: 0.5619\n",
      "3465/3465 [==============================] - 7s 2ms/step - loss: 0.6829 - accuracy: 0.5714\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.7981 - accuracy: 0.5654 - val_loss: 0.6848 - val_accuracy: 0.5644\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6946 - accuracy: 0.5669 - val_loss: 0.6860 - val_accuracy: 0.5608\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6839 - accuracy: 0.5703 - val_loss: 0.6838 - val_accuracy: 0.5677\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6862 - accuracy: 0.5725 - val_loss: 0.6804 - val_accuracy: 0.5798\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6838 - accuracy: 0.5725 - val_loss: 0.6852 - val_accuracy: 0.5655\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6835 - accuracy: 0.5703 - val_loss: 0.6803 - val_accuracy: 0.5794\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6832 - accuracy: 0.5707 - val_loss: 0.6833 - val_accuracy: 0.5703\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6909 - accuracy: 0.5716 - val_loss: 0.6827 - val_accuracy: 0.5721\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6828 - accuracy: 0.5718 - val_loss: 0.6870 - val_accuracy: 0.5557\n",
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6848 - accuracy: 0.5652 - val_loss: 0.6834 - val_accuracy: 0.5692\n",
      "3465/3465 [==============================] - 7s 2ms/step - loss: 0.6855 - accuracy: 0.5619\n",
      "\n",
      "\n",
      "Test score: 0.6841671665509542\n",
      "Test accuracy: 0.5668109854062399\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.8912 - accuracy: 0.5676 - val_loss: 0.6879 - val_accuracy: 0.5539\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6835 - accuracy: 0.5699 - val_loss: 0.6814 - val_accuracy: 0.5779\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6838 - accuracy: 0.5688 - val_loss: 0.6817 - val_accuracy: 0.5758\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6838 - accuracy: 0.5689 - val_loss: 0.6854 - val_accuracy: 0.5622\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6842 - accuracy: 0.5673 - val_loss: 0.6831 - val_accuracy: 0.5714\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6837 - accuracy: 0.5693 - val_loss: 0.6835 - val_accuracy: 0.5696\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6830 - accuracy: 0.5713 - val_loss: 0.6914 - val_accuracy: 0.5465\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6825 - accuracy: 0.5735 - val_loss: 0.6840 - val_accuracy: 0.5685\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6837 - accuracy: 0.5694 - val_loss: 0.6834 - val_accuracy: 0.5696\n",
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6827 - accuracy: 0.5722 - val_loss: 0.6818 - val_accuracy: 0.5754\n",
      "3465/3465 [==============================] - 7s 2ms/step - loss: 0.6802 - accuracy: 0.5804\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.7212 - accuracy: 0.5658 - val_loss: 0.6815 - val_accuracy: 0.5765\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6834 - accuracy: 0.5704 - val_loss: 0.6807 - val_accuracy: 0.5794\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6830 - accuracy: 0.5719 - val_loss: 0.6896 - val_accuracy: 0.5495\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6823 - accuracy: 0.5743 - val_loss: 0.6806 - val_accuracy: 0.5790\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6826 - accuracy: 0.5728 - val_loss: 0.6885 - val_accuracy: 0.5491\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6836 - accuracy: 0.5698 - val_loss: 0.6831 - val_accuracy: 0.5703\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6847 - accuracy: 0.5656 - val_loss: 0.6830 - val_accuracy: 0.5714\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6832 - accuracy: 0.5713 - val_loss: 0.6767 - val_accuracy: 0.5940\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6828 - accuracy: 0.5723 - val_loss: 0.6846 - val_accuracy: 0.5652\n",
      "3465/3465 [==============================] - 7s 2ms/step - loss: 0.6785 - accuracy: 0.5859\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.9947 - accuracy: 0.5680 - val_loss: 0.7023 - val_accuracy: 0.5721\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.7068 - accuracy: 0.5690 - val_loss: 0.6838 - val_accuracy: 0.5703\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6963 - accuracy: 0.5745 - val_loss: 0.6866 - val_accuracy: 0.5546\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6967 - accuracy: 0.5698 - val_loss: 0.6843 - val_accuracy: 0.5655\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6840 - accuracy: 0.5679 - val_loss: 0.6817 - val_accuracy: 0.5769\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6920 - accuracy: 0.5646 - val_loss: 0.6827 - val_accuracy: 0.5710\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6824 - accuracy: 0.5726 - val_loss: 0.6834 - val_accuracy: 0.5765\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6838 - accuracy: 0.5689 - val_loss: 0.6854 - val_accuracy: 0.5622\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6849 - accuracy: 0.5717 - val_loss: 0.6818 - val_accuracy: 0.5747\n",
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6847 - accuracy: 0.5671 - val_loss: 0.6829 - val_accuracy: 0.5721\n",
      "3465/3465 [==============================] - 7s 2ms/step - loss: 0.6826 - accuracy: 0.5732\n",
      "\n",
      "\n",
      "Test score: 0.6804423928260803\n",
      "Test accuracy: 0.5797979831695557\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.8144 - accuracy: 0.5690 - val_loss: 0.6827 - val_accuracy: 0.5725\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6854 - accuracy: 0.5722 - val_loss: 0.6829 - val_accuracy: 0.5717\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6832 - accuracy: 0.5707 - val_loss: 0.6826 - val_accuracy: 0.5728\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6822 - accuracy: 0.5748 - val_loss: 0.6796 - val_accuracy: 0.5823\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6847 - accuracy: 0.5655 - val_loss: 0.6889 - val_accuracy: 0.5469\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6836 - accuracy: 0.5699 - val_loss: 0.6808 - val_accuracy: 0.5787\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6842 - accuracy: 0.5673 - val_loss: 0.6809 - val_accuracy: 0.5783\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6846 - accuracy: 0.5658 - val_loss: 0.6823 - val_accuracy: 0.5736\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6842 - accuracy: 0.5674 - val_loss: 0.6822 - val_accuracy: 0.5747\n",
      "3465/3465 [==============================] - 7s 2ms/step - loss: 0.6835 - accuracy: 0.5694\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 35s 3ms/step - loss: 0.9214 - accuracy: 0.5638 - val_loss: 0.6875 - val_accuracy: 0.5546\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6932 - accuracy: 0.5684 - val_loss: 0.6827 - val_accuracy: 0.5725\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.7245 - accuracy: 0.5738 - val_loss: 0.6847 - val_accuracy: 0.5637\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6835 - accuracy: 0.5741 - val_loss: 0.6809 - val_accuracy: 0.5779\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6887 - accuracy: 0.5711 - val_loss: 0.6803 - val_accuracy: 0.5812\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6837 - accuracy: 0.5700 - val_loss: 0.6843 - val_accuracy: 0.5666\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6824 - accuracy: 0.5738 - val_loss: 0.6841 - val_accuracy: 0.5677\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6837 - accuracy: 0.5689 - val_loss: 0.6816 - val_accuracy: 0.5761\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6830 - accuracy: 0.5710 - val_loss: 0.6826 - val_accuracy: 0.5706\n",
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6858 - accuracy: 0.5739 - val_loss: 0.6818 - val_accuracy: 0.5758\n",
      "3465/3465 [==============================] - 7s 2ms/step - loss: 0.6826 - accuracy: 0.5729\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.7671 - accuracy: 0.5629 - val_loss: 0.6847 - val_accuracy: 0.5761\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6886 - accuracy: 0.5674 - val_loss: 0.6855 - val_accuracy: 0.5619\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6833 - accuracy: 0.5709 - val_loss: 0.6817 - val_accuracy: 0.5754\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6846 - accuracy: 0.5661 - val_loss: 0.6796 - val_accuracy: 0.5845\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6826 - accuracy: 0.5732 - val_loss: 0.6818 - val_accuracy: 0.5750\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6846 - accuracy: 0.5727 - val_loss: 0.6840 - val_accuracy: 0.5706\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6814 - accuracy: 0.5790 - val_loss: 0.6853 - val_accuracy: 0.5670\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6842 - accuracy: 0.5675 - val_loss: 0.6827 - val_accuracy: 0.5721\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 35s 3ms/step - loss: 0.6832 - accuracy: 0.5711 - val_loss: 0.6806 - val_accuracy: 0.5794\n",
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6866 - accuracy: 0.5677 - val_loss: 0.7020 - val_accuracy: 0.5758\n",
      "3465/3465 [==============================] - 7s 2ms/step - loss: 0.6821 - accuracy: 0.5734\n",
      "\n",
      "\n",
      "Test score: 0.6827398141225179\n",
      "Test accuracy: 0.5719095667203268\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "losses = []\n",
    "for d in dropouts:\n",
    "    temp_score = 0\n",
    "    temp_acc = 0\n",
    "    N = 3\n",
    "    for _ in range(N):\n",
    "        model = define_model(shape=[20, 16, 32, 16, 8], dropout=d)\n",
    "        _, history = bnn.fit_model(model, train_dataset, val_dataset, train_dataset, batch_size=256, epochs=10)\n",
    "        score, acc = model.evaluate(test_dataset)\n",
    "        \n",
    "        temp_score += score\n",
    "        temp_acc += acc\n",
    "    print('\\n')\n",
    "    print('Test score:', temp_score/N)\n",
    "    print('Test accuracy:', temp_acc/N)\n",
    "    print('\\n')\n",
    "    \n",
    "    accs.append(temp_acc/N)\n",
    "    losses.append(temp_score/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = [[0.7841, 0.7911, 0.5697],\n",
    "        [0.7573, 0.7680, 0.5619],\n",
    "        [0.5758, 0.5723, 0.5706],\n",
    "        [0.5671, 0.5714, 0.5619],\n",
    "        [0.5804, 0.5859, 0.5732],\n",
    "        [0.5694, 0.5729, 0.5734]\n",
    "       ]\n",
    "losses = [[0.4556, 0.4436, 0.6835],\n",
    "            [0.4797, 0.4795, 0.6856],\n",
    "            [0.6816, 0.6818, 0.6831],\n",
    "            [0.6841, 0.6829, 0.6855],\n",
    "            [0.6802, 0.6785, 0.6826],\n",
    "            [0.6835, 0.6826, 0.6821]\n",
    "         ]\n",
    "\n",
    "accs = np.array(accs).mean(axis=1)\n",
    "losses = np.array(losses).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.71496667, 0.69573333, 0.5729    , 0.5668    , 0.57983333,\n",
       "       0.5719    ])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dropouts, accs)\n",
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.52756667, 0.54826667, 0.68216667, 0.68416667, 0.68043333,\n",
       "       0.68273333])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dropouts, losses)\n",
    "losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndims = np.arange(5, 20, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***************** 5 ********************\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 37s 4ms/step - loss: 0.8719 - accuracy: 0.5602 - val_loss: 0.7100 - val_accuracy: 0.5692\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 35s 3ms/step - loss: 0.6818 - accuracy: 0.5722 - val_loss: 0.6842 - val_accuracy: 0.5666\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 35s 3ms/step - loss: 0.6840 - accuracy: 0.5695 - val_loss: 0.6815 - val_accuracy: 0.5779\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6833 - accuracy: 0.5709 - val_loss: 0.6807 - val_accuracy: 0.5794\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6836 - accuracy: 0.5693 - val_loss: 0.6871 - val_accuracy: 0.5582\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6849 - accuracy: 0.5647 - val_loss: 0.6820 - val_accuracy: 0.5787\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6838 - accuracy: 0.5690 - val_loss: 0.6842 - val_accuracy: 0.5666\n",
      "3465/3465 [==============================] - 7s 2ms/step - loss: 0.6818 - accuracy: 0.5755\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.9284 - accuracy: 0.5620 - val_loss: 0.6858 - val_accuracy: 0.5597\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6849 - accuracy: 0.5733 - val_loss: 0.6828 - val_accuracy: 0.5717\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6838 - accuracy: 0.5686 - val_loss: 0.6827 - val_accuracy: 0.5721\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6854 - accuracy: 0.5630 - val_loss: 0.6842 - val_accuracy: 0.5674\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6844 - accuracy: 0.5669 - val_loss: 0.6829 - val_accuracy: 0.5714\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6852 - accuracy: 0.5637 - val_loss: 0.6832 - val_accuracy: 0.5710\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6836 - accuracy: 0.5694 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6821 - accuracy: 0.5746 - val_loss: 0.6815 - val_accuracy: 0.5772\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6824 - accuracy: 0.5740 - val_loss: 0.6878 - val_accuracy: 0.5542\n",
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6824 - accuracy: 0.5738 - val_loss: 0.6863 - val_accuracy: 0.5593\n",
      "3465/3465 [==============================] - 7s 2ms/step - loss: 0.6844 - accuracy: 0.5662\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 1.0586 - accuracy: 0.5738 - val_loss: 0.6835 - val_accuracy: 0.5692\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6823 - accuracy: 0.5742 - val_loss: 0.6829 - val_accuracy: 0.5717\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6823 - accuracy: 0.5742 - val_loss: 0.6843 - val_accuracy: 0.5674\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6848 - accuracy: 0.5651 - val_loss: 0.6859 - val_accuracy: 0.5612\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6845 - accuracy: 0.5664 - val_loss: 0.6850 - val_accuracy: 0.5637\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6841 - accuracy: 0.5679 - val_loss: 0.6846 - val_accuracy: 0.5652\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6845 - accuracy: 0.5659 - val_loss: 0.6794 - val_accuracy: 0.5885\n",
      "3465/3465 [==============================] - 7s 2ms/step - loss: 0.6844 - accuracy: 0.5671\n",
      "\n",
      "\n",
      "Test score: 0.6835238337516785\n",
      "Test accuracy: 0.5696007609367371\n",
      "\n",
      "\n",
      "\n",
      "***************** 10 ********************\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 1.2578 - accuracy: 0.5679 - val_loss: 0.6855 - val_accuracy: 0.5630\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6748 - accuracy: 0.6011 - val_loss: 0.6448 - val_accuracy: 0.6342\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6533 - accuracy: 0.6334 - val_loss: 0.6279 - val_accuracy: 0.6648\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6431 - accuracy: 0.6452 - val_loss: 0.6457 - val_accuracy: 0.6090\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6356 - accuracy: 0.6500 - val_loss: 0.5970 - val_accuracy: 0.6762\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6202 - accuracy: 0.6534 - val_loss: 0.6140 - val_accuracy: 0.6634\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6228 - accuracy: 0.6556 - val_loss: 0.5974 - val_accuracy: 0.6783\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6275 - accuracy: 0.6526 - val_loss: 0.5922 - val_accuracy: 0.6897\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6092 - accuracy: 0.6614 - val_loss: 0.5893 - val_accuracy: 0.6926\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6084 - accuracy: 0.6621 - val_loss: 0.5856 - val_accuracy: 0.6787\n",
      "3465/3465 [==============================] - 7s 2ms/step - loss: 0.6011 - accuracy: 0.6626\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.7530 - accuracy: 0.5685 - val_loss: 0.6809 - val_accuracy: 0.5772\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6860 - accuracy: 0.5622 - val_loss: 0.6841 - val_accuracy: 0.5674\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6840 - accuracy: 0.5670 - val_loss: 0.6829 - val_accuracy: 0.5779\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6835 - accuracy: 0.5704 - val_loss: 0.6892 - val_accuracy: 0.5487\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6851 - accuracy: 0.5641 - val_loss: 0.6850 - val_accuracy: 0.5641\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6844 - accuracy: 0.5665 - val_loss: 0.6854 - val_accuracy: 0.5622\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6845 - accuracy: 0.5659 - val_loss: 0.6816 - val_accuracy: 0.5765\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6847 - accuracy: 0.5654 - val_loss: 0.6844 - val_accuracy: 0.5670\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6849 - accuracy: 0.5649 - val_loss: 0.6831 - val_accuracy: 0.5706\n",
      "3465/3465 [==============================] - 7s 2ms/step - loss: 0.6832 - accuracy: 0.5706\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.8962 - accuracy: 0.5637 - val_loss: 0.6742 - val_accuracy: 0.5882\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6782 - accuracy: 0.5819 - val_loss: 0.6468 - val_accuracy: 0.6210\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6582 - accuracy: 0.6037 - val_loss: 0.6419 - val_accuracy: 0.6349\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6432 - accuracy: 0.6147 - val_loss: 0.6155 - val_accuracy: 0.6378\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6348 - accuracy: 0.6222 - val_loss: 0.6258 - val_accuracy: 0.6119\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6336 - accuracy: 0.6170 - val_loss: 0.6215 - val_accuracy: 0.6437\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6363 - accuracy: 0.6168 - val_loss: 0.6144 - val_accuracy: 0.6294\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6230 - accuracy: 0.6500 - val_loss: 0.5977 - val_accuracy: 0.6743\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6157 - accuracy: 0.6629 - val_loss: 0.6827 - val_accuracy: 0.6860\n",
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6157 - accuracy: 0.6544 - val_loss: 0.6143 - val_accuracy: 0.6732\n",
      "3465/3465 [==============================] - 7s 2ms/step - loss: 0.6065 - accuracy: 0.6615\n",
      "\n",
      "\n",
      "Test score: 0.6302804946899414\n",
      "Test accuracy: 0.6315536300341288\n",
      "\n",
      "\n",
      "\n",
      "***************** 15 ********************\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.7695 - accuracy: 0.5703 - val_loss: 0.6829 - val_accuracy: 0.5725\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6851 - accuracy: 0.5639 - val_loss: 0.6851 - val_accuracy: 0.5641\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6817 - accuracy: 0.5760 - val_loss: 0.6842 - val_accuracy: 0.5677\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6828 - accuracy: 0.5723 - val_loss: 0.6837 - val_accuracy: 0.5696\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6841 - accuracy: 0.5682 - val_loss: 0.6838 - val_accuracy: 0.5681\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6840 - accuracy: 0.5680 - val_loss: 0.6826 - val_accuracy: 0.5750\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6838 - accuracy: 0.5690 - val_loss: 0.6833 - val_accuracy: 0.5703\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6844 - accuracy: 0.5668 - val_loss: 0.6842 - val_accuracy: 0.5670\n",
      "3465/3465 [==============================] - 7s 2ms/step - loss: 0.6828 - accuracy: 0.5720\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.8074 - accuracy: 0.5776 - val_loss: 0.6840 - val_accuracy: 0.5677\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6859 - accuracy: 0.5833 - val_loss: 0.6739 - val_accuracy: 0.5889\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6720 - accuracy: 0.5992 - val_loss: 0.6692 - val_accuracy: 0.5973\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6690 - accuracy: 0.6045 - val_loss: 0.6572 - val_accuracy: 0.6364\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6493 - accuracy: 0.6374 - val_loss: 0.6400 - val_accuracy: 0.6528\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6516 - accuracy: 0.6430 - val_loss: 0.6719 - val_accuracy: 0.5878\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6353 - accuracy: 0.6526 - val_loss: 0.6177 - val_accuracy: 0.6710\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6236 - accuracy: 0.6666 - val_loss: 0.5896 - val_accuracy: 0.6857\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6059 - accuracy: 0.6760 - val_loss: 0.5832 - val_accuracy: 0.7003\n",
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.5923 - accuracy: 0.6821 - val_loss: 0.6106 - val_accuracy: 0.6360\n",
      "3465/3465 [==============================] - 7s 2ms/step - loss: 0.6152 - accuracy: 0.6355\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.9641 - accuracy: 0.5648 - val_loss: 0.6787 - val_accuracy: 0.5798\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6839 - accuracy: 0.5681 - val_loss: 0.6836 - val_accuracy: 0.5692\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6848 - accuracy: 0.5651 - val_loss: 0.6829 - val_accuracy: 0.5714\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.6840 - accuracy: 0.5684 - val_loss: 0.6866 - val_accuracy: 0.5579\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6834 - accuracy: 0.5705 - val_loss: 0.6799 - val_accuracy: 0.5820\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6834 - accuracy: 0.5702 - val_loss: 0.6851 - val_accuracy: 0.5652\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6830 - accuracy: 0.5719 - val_loss: 0.6834 - val_accuracy: 0.5696\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6833 - accuracy: 0.5707 - val_loss: 0.6754 - val_accuracy: 0.5977\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6826 - accuracy: 0.5733 - val_loss: 0.6833 - val_accuracy: 0.5703\n",
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6853 - accuracy: 0.5628 - val_loss: 0.6859 - val_accuracy: 0.5604\n",
      "3465/3465 [==============================] - 7s 2ms/step - loss: 0.6849 - accuracy: 0.5645\n",
      "\n",
      "\n",
      "Test score: 0.6609857479731241\n",
      "Test accuracy: 0.5906685789426168\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "losses = []\n",
    "for d in ndims:\n",
    "    \n",
    "    print('\\n***************** {} ********************\\n'.format(d))\n",
    "    \n",
    "    cells_df   = bpreprocess.tube_to_df(ex)\n",
    "    cyto_dataset = bpreprocess.df_to_train_tensor(cells_df, use=USE, pca=d)\n",
    "\n",
    "    train_dataset, val_dataset, test_dataset = bpreprocess.split_dataset(cyto_dataset, VAL, TEST)\n",
    "    \n",
    "    temp_score = 0\n",
    "    temp_acc = 0\n",
    "    N = 3\n",
    "    for _ in range(N):\n",
    "        model = bnn.define_model(shape=[20, 16, 32, 16, 8], dropout=0.1)\n",
    "        _, history = bnn.fit_model(model, train_dataset, val_dataset, train_dataset, epochs=10)\n",
    "        score, acc = model.evaluate(test_dataset)\n",
    "        \n",
    "        temp_score += score\n",
    "        temp_acc += acc\n",
    "    print('\\n')\n",
    "    print('Test score:', temp_score/N)\n",
    "    print('Test accuracy:', temp_acc/N)\n",
    "    print('\\n')\n",
    "    \n",
    "    accs.append(temp_acc/N)\n",
    "    losses.append(temp_score/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5696007609367371, 0.6315536300341288, 0.5906685789426168]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ndims, accs)\n",
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6835238337516785, 0.6302804946899414, 0.6609857479731241]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ndims, losses)\n",
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***************** 20 ********************\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 35s 3ms/step - loss: 0.9660 - accuracy: 0.6076 - val_loss: 0.6073 - val_accuracy: 0.6751\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 35s 3ms/step - loss: 0.6214 - accuracy: 0.6772 - val_loss: 0.5620 - val_accuracy: 0.7229\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.5996 - accuracy: 0.6843 - val_loss: 0.5929 - val_accuracy: 0.7068\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.5732 - accuracy: 0.7030 - val_loss: 0.5647 - val_accuracy: 0.6962\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.5758 - accuracy: 0.7035 - val_loss: 0.5378 - val_accuracy: 0.7130\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.5743 - accuracy: 0.7066 - val_loss: 0.5357 - val_accuracy: 0.7240\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.5571 - accuracy: 0.7146 - val_loss: 0.5207 - val_accuracy: 0.7295\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.5583 - accuracy: 0.7193 - val_loss: 0.5389 - val_accuracy: 0.7327\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.5486 - accuracy: 0.7226 - val_loss: 0.5192 - val_accuracy: 0.7408\n",
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.5652 - accuracy: 0.7236 - val_loss: 0.5612 - val_accuracy: 0.6977\n",
      "3465/3465 [==============================] - 7s 2ms/step - loss: 0.5542 - accuracy: 0.7082\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 1.0485 - accuracy: 0.6264 - val_loss: 0.6547 - val_accuracy: 0.6557\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6288 - accuracy: 0.6680 - val_loss: 0.6078 - val_accuracy: 0.6893\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6139 - accuracy: 0.6812 - val_loss: 0.5844 - val_accuracy: 0.7119\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6157 - accuracy: 0.6826 - val_loss: 0.6259 - val_accuracy: 0.6962\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.5967 - accuracy: 0.6963 - val_loss: 0.5678 - val_accuracy: 0.7236\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6023 - accuracy: 0.6922 - val_loss: 0.5967 - val_accuracy: 0.7163\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.5857 - accuracy: 0.6980 - val_loss: 0.5656 - val_accuracy: 0.7127\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.5837 - accuracy: 0.7029 - val_loss: 0.5760 - val_accuracy: 0.7116\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6014 - accuracy: 0.7024 - val_loss: 0.5991 - val_accuracy: 0.6886\n",
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 34s 3ms/step - loss: 0.5986 - accuracy: 0.6973 - val_loss: 0.5903 - val_accuracy: 0.6937\n",
      "3465/3465 [==============================] - 7s 2ms/step - loss: 0.5714 - accuracy: 0.7128\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.8078 - accuracy: 0.5800 - val_loss: 0.6792 - val_accuracy: 0.5805\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6814 - accuracy: 0.5845 - val_loss: 0.6802 - val_accuracy: 0.5911\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6708 - accuracy: 0.5996 - val_loss: 0.6623 - val_accuracy: 0.6152\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6650 - accuracy: 0.6111 - val_loss: 0.6463 - val_accuracy: 0.6280\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6524 - accuracy: 0.6439 - val_loss: 0.6106 - val_accuracy: 0.6824\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6191 - accuracy: 0.6743 - val_loss: 0.5966 - val_accuracy: 0.6981\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.5979 - accuracy: 0.7007 - val_loss: 0.5783 - val_accuracy: 0.7087\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.5898 - accuracy: 0.7028 - val_loss: 0.5896 - val_accuracy: 0.7024\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.5877 - accuracy: 0.7010 - val_loss: 0.5714 - val_accuracy: 0.7127\n",
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.5733 - accuracy: 0.7149 - val_loss: 0.5511 - val_accuracy: 0.7251\n",
      "3465/3465 [==============================] - 7s 2ms/step - loss: 0.5444 - accuracy: 0.7342\n",
      "\n",
      "\n",
      "Test score: 0.5566580494244894\n",
      "Test accuracy: 0.7184223135312399\n",
      "\n",
      "\n",
      "\n",
      "***************** 25 ********************\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6932 - accuracy: 0.5874 - val_loss: 0.6396 - val_accuracy: 0.6097\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6228 - accuracy: 0.6230 - val_loss: 0.5804 - val_accuracy: 0.6846\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.5930 - accuracy: 0.6875 - val_loss: 0.5515 - val_accuracy: 0.7006\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.5613 - accuracy: 0.7014 - val_loss: 0.5260 - val_accuracy: 0.7357\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.5525 - accuracy: 0.7193 - val_loss: 0.5213 - val_accuracy: 0.7444\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.5507 - accuracy: 0.7206 - val_loss: 0.4923 - val_accuracy: 0.7466\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.5424 - accuracy: 0.7150 - val_loss: 0.5204 - val_accuracy: 0.7379\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.5145 - accuracy: 0.7294 - val_loss: 0.5064 - val_accuracy: 0.7317\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.4987 - accuracy: 0.7500 - val_loss: 0.5310 - val_accuracy: 0.7536\n",
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.5056 - accuracy: 0.7503 - val_loss: 0.4602 - val_accuracy: 0.7649\n",
      "3465/3465 [==============================] - 7s 2ms/step - loss: 0.4560 - accuracy: 0.7775\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.7944 - accuracy: 0.5811 - val_loss: 0.6780 - val_accuracy: 0.5878\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6801 - accuracy: 0.5809 - val_loss: 0.6764 - val_accuracy: 0.5918\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6911 - accuracy: 0.5817 - val_loss: 0.6843 - val_accuracy: 0.5820\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6978 - accuracy: 0.5782 - val_loss: 0.6797 - val_accuracy: 0.5820\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 32s 3ms/step - loss: 0.6988 - accuracy: 0.5740 - val_loss: 0.6756 - val_accuracy: 0.5944\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 32s 3ms/step - loss: 0.6827 - accuracy: 0.5822 - val_loss: 0.6804 - val_accuracy: 0.5798\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 32s 3ms/step - loss: 0.6800 - accuracy: 0.5817 - val_loss: 0.6833 - val_accuracy: 0.5710\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6797 - accuracy: 0.5821 - val_loss: 0.6834 - val_accuracy: 0.5736\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6786 - accuracy: 0.5857 - val_loss: 0.6834 - val_accuracy: 0.5714\n",
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6802 - accuracy: 0.5807 - val_loss: 0.6765 - val_accuracy: 0.5911\n",
      "3465/3465 [==============================] - 7s 2ms/step - loss: 0.6829 - accuracy: 0.5726\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.8654 - accuracy: 0.5832 - val_loss: 0.6783 - val_accuracy: 0.5823\n",
      "Epoch 2/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6788 - accuracy: 0.5935 - val_loss: 0.6811 - val_accuracy: 0.6137\n",
      "Epoch 3/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.6254 - accuracy: 0.6105 - val_loss: 0.5955 - val_accuracy: 0.6291\n",
      "Epoch 4/10\n",
      "10270/10270 [==============================] - 32s 3ms/step - loss: 0.5946 - accuracy: 0.6587 - val_loss: 0.5453 - val_accuracy: 0.7167\n",
      "Epoch 5/10\n",
      "10270/10270 [==============================] - 32s 3ms/step - loss: 0.5563 - accuracy: 0.6985 - val_loss: 0.5364 - val_accuracy: 0.7218\n",
      "Epoch 6/10\n",
      "10270/10270 [==============================] - 32s 3ms/step - loss: 0.5463 - accuracy: 0.7137 - val_loss: 0.5205 - val_accuracy: 0.7444\n",
      "Epoch 7/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.5244 - accuracy: 0.7293 - val_loss: 0.5009 - val_accuracy: 0.7422\n",
      "Epoch 8/10\n",
      "10270/10270 [==============================] - 33s 3ms/step - loss: 0.5054 - accuracy: 0.7443 - val_loss: 0.5343 - val_accuracy: 0.7474\n",
      "Epoch 9/10\n",
      "10270/10270 [==============================] - 32s 3ms/step - loss: 0.5042 - accuracy: 0.7500 - val_loss: 0.4968 - val_accuracy: 0.7470\n",
      "Epoch 10/10\n",
      "10270/10270 [==============================] - 32s 3ms/step - loss: 0.5159 - accuracy: 0.7502 - val_loss: 0.4890 - val_accuracy: 0.7455\n",
      "3465/3465 [==============================] - 7s 2ms/step - loss: 0.4901 - accuracy: 0.7582\n",
      "\n",
      "\n",
      "Test score: 0.5430114964644114\n",
      "Test accuracy: 0.7027417023976644\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "losses = []\n",
    "for d in [20, 25]:\n",
    "    \n",
    "    print('\\n***************** {} ********************\\n'.format(d))\n",
    "    \n",
    "    cells_df   = bpreprocess.tube_to_df(ex)\n",
    "    cyto_dataset = bpreprocess.df_to_train_tensor(cells_df, use=USE, pca=d)\n",
    "\n",
    "    train_dataset, val_dataset, test_dataset = bpreprocess.split_dataset(cyto_dataset, VAL, TEST)\n",
    "    \n",
    "    temp_score = 0\n",
    "    temp_acc = 0\n",
    "    N = 3\n",
    "    for _ in range(N):\n",
    "        model = bnn.define_model(shape=[20, 16, 32, 16, 8], dropout=0.1)\n",
    "        _, history = bnn.fit_model(model, train_dataset, val_dataset, train_dataset, epochs=10)\n",
    "        score, acc = model.evaluate(test_dataset)\n",
    "        \n",
    "        temp_score += score\n",
    "        temp_acc += acc\n",
    "    print('\\n')\n",
    "    print('Test score:', temp_score/N)\n",
    "    print('Test accuracy:', temp_acc/N)\n",
    "    print('\\n')\n",
    "    \n",
    "    accs.append(temp_acc/N)\n",
    "    losses.append(temp_score/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7184223135312399, 0.7027417023976644]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5566580494244894, 0.5430114964644114]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5696007609367371,\n",
       " 0.6315536300341288,\n",
       " 0.5906685789426168,\n",
       " 0.7184223135312399,\n",
       " 0.7027417023976644]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# acc\n",
    "[0.5696007609367371, 0.6315536300341288, 0.5906685789426168, 0.7184223135312399, 0.7027417023976644]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6835238337516785,\n",
       " 0.6302804946899414,\n",
       " 0.6609857479731241,\n",
       " 0.5566580494244894,\n",
       " 0.5430114964644114]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss\n",
    "[0.6835238337516785, 0.6302804946899414, 0.6609857479731241, 0.5566580494244894, 0.5430114964644114]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
