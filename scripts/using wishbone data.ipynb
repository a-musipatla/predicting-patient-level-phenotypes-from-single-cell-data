{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, 'dnn/')\n",
    "\n",
    "# del bnn\n",
    "import bcell_nn as bnn\n",
    "import bcell_plot\n",
    "import bcell_preprocess as bpreprocess\n",
    "# import bcell_driver\n",
    "\n",
    "# System arguments\n",
    "import argparse\n",
    "# data management\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# flow cytometry libraries\n",
    "import cytoflow as flow\n",
    "# user defined functions\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29238 29238\n"
     ]
    }
   ],
   "source": [
    "# concat wishbone data\n",
    "branches = pd.concat([pd.read_csv('../data/Wishbone_branches/branches_bcr_signalling.csv', index_col=0), pd.read_csv('../data/Wishbone_branches/branches_basal_signalling.csv', index_col=0)])\n",
    "trajectories = pd.concat([pd.read_csv('../data/Wishbone_trajectories/trajectory_bcr_signalling.csv', index_col=0), pd.read_csv('../data/Wishbone_trajectories/trajectory_basal_signalling.csv', index_col=0)])\n",
    "\n",
    "branches.columns = ['branch']\n",
    "trajectories.columns = ['trajectory']\n",
    "\n",
    "branches = branches[~branches.index.duplicated(keep='first')]\n",
    "trajectories = trajectories[~trajectories.index.duplicated(keep='first')]\n",
    "\n",
    "print(len(branches), len(trajectories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29702, 23)\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('../data/Bcell_signalling_proteins/matrix_basal_signalling_markers_#2.csv', index_col=0)\n",
    "df2 = pd.read_csv('../data/Bcell_signalling_proteins/matrix_bcr_signalling_markers_#2.csv', index_col=0)\n",
    "df1['bcr'] = 0\n",
    "df2['bcr'] = 1\n",
    "\n",
    "signal_df = pd.concat([df1, df2])\n",
    "signal_df.head()\n",
    "\n",
    "print(signal_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>110_114-CD3</th>\n",
       "      <th>111-CD3</th>\n",
       "      <th>112-CD3</th>\n",
       "      <th>114-CD3</th>\n",
       "      <th>141-pPLCgamma2</th>\n",
       "      <th>150-pSTAT5</th>\n",
       "      <th>151-pERK1/2</th>\n",
       "      <th>152-Ki67</th>\n",
       "      <th>153-pMAPKAPK2</th>\n",
       "      <th>154-pSHP2</th>\n",
       "      <th>...</th>\n",
       "      <th>168-pH3</th>\n",
       "      <th>169-pP38</th>\n",
       "      <th>171-pBtk/Itk</th>\n",
       "      <th>172-pS6</th>\n",
       "      <th>174-pSrcFK</th>\n",
       "      <th>175-pCrkL</th>\n",
       "      <th>176-pCREB</th>\n",
       "      <th>bcr</th>\n",
       "      <th>branch</th>\n",
       "      <th>trajectory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.171318</td>\n",
       "      <td>-0.450817</td>\n",
       "      <td>-0.608567</td>\n",
       "      <td>6.029278</td>\n",
       "      <td>9.331525</td>\n",
       "      <td>-0.845049</td>\n",
       "      <td>14.676166</td>\n",
       "      <td>1.818566</td>\n",
       "      <td>2.874730</td>\n",
       "      <td>17.832912</td>\n",
       "      <td>...</td>\n",
       "      <td>8.435942</td>\n",
       "      <td>76.529343</td>\n",
       "      <td>4.326055</td>\n",
       "      <td>0.655243</td>\n",
       "      <td>2.677969</td>\n",
       "      <td>-1.446438</td>\n",
       "      <td>2.424710</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.264602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-13.813409</td>\n",
       "      <td>0.754631</td>\n",
       "      <td>-1.202560</td>\n",
       "      <td>-11.105885</td>\n",
       "      <td>84.821815</td>\n",
       "      <td>7.536618</td>\n",
       "      <td>38.950451</td>\n",
       "      <td>1.903706</td>\n",
       "      <td>13.491470</td>\n",
       "      <td>26.370272</td>\n",
       "      <td>...</td>\n",
       "      <td>64.488258</td>\n",
       "      <td>115.278679</td>\n",
       "      <td>17.951509</td>\n",
       "      <td>29.039434</td>\n",
       "      <td>62.710323</td>\n",
       "      <td>6.291503</td>\n",
       "      <td>31.427765</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.057659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.352439</td>\n",
       "      <td>0.341111</td>\n",
       "      <td>-1.615738</td>\n",
       "      <td>-0.122326</td>\n",
       "      <td>1.303879</td>\n",
       "      <td>2.899095</td>\n",
       "      <td>34.662552</td>\n",
       "      <td>-0.275870</td>\n",
       "      <td>15.783648</td>\n",
       "      <td>17.620398</td>\n",
       "      <td>...</td>\n",
       "      <td>5.382995</td>\n",
       "      <td>101.783089</td>\n",
       "      <td>6.834910</td>\n",
       "      <td>28.550144</td>\n",
       "      <td>34.058968</td>\n",
       "      <td>4.541006</td>\n",
       "      <td>18.538198</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.058571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-2.647034</td>\n",
       "      <td>-0.061374</td>\n",
       "      <td>2.036048</td>\n",
       "      <td>0.190818</td>\n",
       "      <td>7.546767</td>\n",
       "      <td>10.631545</td>\n",
       "      <td>16.491894</td>\n",
       "      <td>3.028020</td>\n",
       "      <td>6.266270</td>\n",
       "      <td>4.856538</td>\n",
       "      <td>...</td>\n",
       "      <td>22.576366</td>\n",
       "      <td>151.329102</td>\n",
       "      <td>1.419633</td>\n",
       "      <td>33.557350</td>\n",
       "      <td>11.859700</td>\n",
       "      <td>8.606210</td>\n",
       "      <td>12.979078</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.058252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.013113</td>\n",
       "      <td>-0.688039</td>\n",
       "      <td>0.232603</td>\n",
       "      <td>-0.838379</td>\n",
       "      <td>18.820129</td>\n",
       "      <td>8.742398</td>\n",
       "      <td>22.354654</td>\n",
       "      <td>-3.074918</td>\n",
       "      <td>1.138519</td>\n",
       "      <td>1.086791</td>\n",
       "      <td>...</td>\n",
       "      <td>7.996578</td>\n",
       "      <td>63.526962</td>\n",
       "      <td>29.082439</td>\n",
       "      <td>29.092857</td>\n",
       "      <td>21.322346</td>\n",
       "      <td>4.467139</td>\n",
       "      <td>10.174027</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.058832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471739</th>\n",
       "      <td>-2.799587</td>\n",
       "      <td>-0.607517</td>\n",
       "      <td>-0.835767</td>\n",
       "      <td>-0.980455</td>\n",
       "      <td>322.782074</td>\n",
       "      <td>16.849302</td>\n",
       "      <td>95.306534</td>\n",
       "      <td>0.570192</td>\n",
       "      <td>29.137192</td>\n",
       "      <td>51.822701</td>\n",
       "      <td>...</td>\n",
       "      <td>35.923096</td>\n",
       "      <td>39.349442</td>\n",
       "      <td>6.410147</td>\n",
       "      <td>93.473450</td>\n",
       "      <td>62.584103</td>\n",
       "      <td>15.369135</td>\n",
       "      <td>11.190707</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.055541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471770</th>\n",
       "      <td>23.045057</td>\n",
       "      <td>14.629941</td>\n",
       "      <td>-0.410597</td>\n",
       "      <td>3.637822</td>\n",
       "      <td>27.408026</td>\n",
       "      <td>11.361174</td>\n",
       "      <td>99.938850</td>\n",
       "      <td>0.273641</td>\n",
       "      <td>34.619743</td>\n",
       "      <td>14.185965</td>\n",
       "      <td>...</td>\n",
       "      <td>55.876968</td>\n",
       "      <td>47.855972</td>\n",
       "      <td>34.769245</td>\n",
       "      <td>37.195259</td>\n",
       "      <td>63.399906</td>\n",
       "      <td>8.008888</td>\n",
       "      <td>33.619480</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.058429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471970</th>\n",
       "      <td>3.909767</td>\n",
       "      <td>-0.020133</td>\n",
       "      <td>-1.045324</td>\n",
       "      <td>5.840205</td>\n",
       "      <td>17.922468</td>\n",
       "      <td>11.660793</td>\n",
       "      <td>22.337528</td>\n",
       "      <td>-0.332774</td>\n",
       "      <td>6.761919</td>\n",
       "      <td>0.654727</td>\n",
       "      <td>...</td>\n",
       "      <td>40.555592</td>\n",
       "      <td>62.141502</td>\n",
       "      <td>6.441080</td>\n",
       "      <td>88.479965</td>\n",
       "      <td>40.739178</td>\n",
       "      <td>5.325276</td>\n",
       "      <td>50.402176</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.058701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472012</th>\n",
       "      <td>3.447302</td>\n",
       "      <td>-0.439497</td>\n",
       "      <td>3.060533</td>\n",
       "      <td>-0.869404</td>\n",
       "      <td>6.576580</td>\n",
       "      <td>6.294831</td>\n",
       "      <td>15.881731</td>\n",
       "      <td>-0.756070</td>\n",
       "      <td>11.646162</td>\n",
       "      <td>4.539165</td>\n",
       "      <td>...</td>\n",
       "      <td>21.692110</td>\n",
       "      <td>76.187645</td>\n",
       "      <td>11.464962</td>\n",
       "      <td>23.188345</td>\n",
       "      <td>62.133389</td>\n",
       "      <td>2.555749</td>\n",
       "      <td>19.671515</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.058686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472030</th>\n",
       "      <td>-2.324584</td>\n",
       "      <td>-0.199424</td>\n",
       "      <td>-0.206428</td>\n",
       "      <td>-0.955111</td>\n",
       "      <td>104.880836</td>\n",
       "      <td>31.458118</td>\n",
       "      <td>57.936855</td>\n",
       "      <td>0.392115</td>\n",
       "      <td>14.913630</td>\n",
       "      <td>29.323494</td>\n",
       "      <td>...</td>\n",
       "      <td>84.039284</td>\n",
       "      <td>171.514740</td>\n",
       "      <td>52.213802</td>\n",
       "      <td>18.679729</td>\n",
       "      <td>53.715473</td>\n",
       "      <td>9.857834</td>\n",
       "      <td>25.311768</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.056389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29702 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        110_114-CD3    111-CD3   112-CD3    114-CD3  141-pPLCgamma2  \\\n",
       "8          5.171318  -0.450817 -0.608567   6.029278        9.331525   \n",
       "12       -13.813409   0.754631 -1.202560 -11.105885       84.821815   \n",
       "30         0.352439   0.341111 -1.615738  -0.122326        1.303879   \n",
       "45        -2.647034  -0.061374  2.036048   0.190818        7.546767   \n",
       "73         0.013113  -0.688039  0.232603  -0.838379       18.820129   \n",
       "...             ...        ...       ...        ...             ...   \n",
       "471739    -2.799587  -0.607517 -0.835767  -0.980455      322.782074   \n",
       "471770    23.045057  14.629941 -0.410597   3.637822       27.408026   \n",
       "471970     3.909767  -0.020133 -1.045324   5.840205       17.922468   \n",
       "472012     3.447302  -0.439497  3.060533  -0.869404        6.576580   \n",
       "472030    -2.324584  -0.199424 -0.206428  -0.955111      104.880836   \n",
       "\n",
       "        150-pSTAT5  151-pERK1/2  152-Ki67  153-pMAPKAPK2  154-pSHP2  ...  \\\n",
       "8        -0.845049    14.676166  1.818566       2.874730  17.832912  ...   \n",
       "12        7.536618    38.950451  1.903706      13.491470  26.370272  ...   \n",
       "30        2.899095    34.662552 -0.275870      15.783648  17.620398  ...   \n",
       "45       10.631545    16.491894  3.028020       6.266270   4.856538  ...   \n",
       "73        8.742398    22.354654 -3.074918       1.138519   1.086791  ...   \n",
       "...            ...          ...       ...            ...        ...  ...   \n",
       "471739   16.849302    95.306534  0.570192      29.137192  51.822701  ...   \n",
       "471770   11.361174    99.938850  0.273641      34.619743  14.185965  ...   \n",
       "471970   11.660793    22.337528 -0.332774       6.761919   0.654727  ...   \n",
       "472012    6.294831    15.881731 -0.756070      11.646162   4.539165  ...   \n",
       "472030   31.458118    57.936855  0.392115      14.913630  29.323494  ...   \n",
       "\n",
       "          168-pH3    169-pP38  171-pBtk/Itk    172-pS6  174-pSrcFK  175-pCrkL  \\\n",
       "8        8.435942   76.529343      4.326055   0.655243    2.677969  -1.446438   \n",
       "12      64.488258  115.278679     17.951509  29.039434   62.710323   6.291503   \n",
       "30       5.382995  101.783089      6.834910  28.550144   34.058968   4.541006   \n",
       "45      22.576366  151.329102      1.419633  33.557350   11.859700   8.606210   \n",
       "73       7.996578   63.526962     29.082439  29.092857   21.322346   4.467139   \n",
       "...           ...         ...           ...        ...         ...        ...   \n",
       "471739  35.923096   39.349442      6.410147  93.473450   62.584103  15.369135   \n",
       "471770  55.876968   47.855972     34.769245  37.195259   63.399906   8.008888   \n",
       "471970  40.555592   62.141502      6.441080  88.479965   40.739178   5.325276   \n",
       "472012  21.692110   76.187645     11.464962  23.188345   62.133389   2.555749   \n",
       "472030  84.039284  171.514740     52.213802  18.679729   53.715473   9.857834   \n",
       "\n",
       "        176-pCREB  bcr  branch  trajectory  \n",
       "8        2.424710    0       2    0.264602  \n",
       "12      31.427765    1       1    0.057659  \n",
       "30      18.538198    1       1    0.058571  \n",
       "45      12.979078    1       1    0.058252  \n",
       "73      10.174027    1       1    0.058832  \n",
       "...           ...  ...     ...         ...  \n",
       "471739  11.190707    1       1    0.055541  \n",
       "471770  33.619480    1       1    0.058429  \n",
       "471970  50.402176    1       1    0.058701  \n",
       "472012  19.671515    1       1    0.058686  \n",
       "472030  25.311768    1       1    0.056389  \n",
       "\n",
       "[29702 rows x 25 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_df = signal_df.merge(branches, left_index=True, right_index=True, how='inner')\n",
    "signal_df = signal_df.merge(trajectories, left_index=True, right_index=True, how='inner')\n",
    "signal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pop off last .1 as test data\n",
    "np.random.seed(0)\n",
    "signal_df_train = signal_df.sample(frac=0.8)\n",
    "\n",
    "signal_test = signal_df[~signal_df.index.isin(signal_df_train.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "signal_df_train.to_csv('../data/signal_train.csv')\n",
    "signal_test.to_csv('../data/signal_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29702, 14)\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv( '../data/Bcell_surface_marker/matrix_basal_surface_markers_#2.csv', index_col=0)\n",
    "df2 = pd.read_csv( '../data/Bcell_surface_marker/matrix_bcr_surface_markers_#2.csv', index_col=0)\n",
    "\n",
    "df1['bcr'] = 0\n",
    "df2['bcr'] = 1\n",
    "\n",
    "surface_df = pd.concat([df1, df2])\n",
    "surface_df.head()\n",
    "print(surface_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>110-CD3</th>\n",
       "      <th>115-CD45</th>\n",
       "      <th>139-CD45RA</th>\n",
       "      <th>142-CD19</th>\n",
       "      <th>144-CD11b</th>\n",
       "      <th>145-CD4</th>\n",
       "      <th>146-CD8</th>\n",
       "      <th>147-CD20</th>\n",
       "      <th>148-CD34</th>\n",
       "      <th>158-CD33</th>\n",
       "      <th>160-CD123</th>\n",
       "      <th>167-CD38</th>\n",
       "      <th>170-CD90</th>\n",
       "      <th>bcr</th>\n",
       "      <th>branch</th>\n",
       "      <th>trajectory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.072176</td>\n",
       "      <td>219.463165</td>\n",
       "      <td>73.935654</td>\n",
       "      <td>36.863819</td>\n",
       "      <td>-1.054267</td>\n",
       "      <td>-0.147575</td>\n",
       "      <td>-0.102538</td>\n",
       "      <td>32.607048</td>\n",
       "      <td>-0.249687</td>\n",
       "      <td>0.067650</td>\n",
       "      <td>6.987092</td>\n",
       "      <td>37.832825</td>\n",
       "      <td>2.822956</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.264602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-2.307435</td>\n",
       "      <td>204.438171</td>\n",
       "      <td>77.867607</td>\n",
       "      <td>42.641132</td>\n",
       "      <td>-0.285443</td>\n",
       "      <td>-0.372202</td>\n",
       "      <td>-4.427719</td>\n",
       "      <td>17.261219</td>\n",
       "      <td>-0.488574</td>\n",
       "      <td>-3.711010</td>\n",
       "      <td>34.505669</td>\n",
       "      <td>19.478870</td>\n",
       "      <td>5.564790</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.057659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.746720</td>\n",
       "      <td>284.282013</td>\n",
       "      <td>28.760956</td>\n",
       "      <td>38.499954</td>\n",
       "      <td>1.275578</td>\n",
       "      <td>-1.653929</td>\n",
       "      <td>-0.024098</td>\n",
       "      <td>39.808941</td>\n",
       "      <td>-0.463562</td>\n",
       "      <td>0.135652</td>\n",
       "      <td>50.319153</td>\n",
       "      <td>22.642670</td>\n",
       "      <td>-0.418175</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.058571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-4.815868</td>\n",
       "      <td>234.770752</td>\n",
       "      <td>62.574379</td>\n",
       "      <td>44.692940</td>\n",
       "      <td>3.540209</td>\n",
       "      <td>-0.526092</td>\n",
       "      <td>0.172865</td>\n",
       "      <td>40.247784</td>\n",
       "      <td>2.179591</td>\n",
       "      <td>5.230491</td>\n",
       "      <td>-0.804634</td>\n",
       "      <td>59.010201</td>\n",
       "      <td>-0.574145</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.058252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1.310114</td>\n",
       "      <td>108.836357</td>\n",
       "      <td>48.661461</td>\n",
       "      <td>34.506725</td>\n",
       "      <td>-1.216142</td>\n",
       "      <td>-0.464221</td>\n",
       "      <td>2.820165</td>\n",
       "      <td>37.411366</td>\n",
       "      <td>-0.315401</td>\n",
       "      <td>0.303836</td>\n",
       "      <td>22.056704</td>\n",
       "      <td>23.780251</td>\n",
       "      <td>4.541167</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.058832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471739</th>\n",
       "      <td>-0.383450</td>\n",
       "      <td>246.238373</td>\n",
       "      <td>50.226032</td>\n",
       "      <td>14.160948</td>\n",
       "      <td>-0.589054</td>\n",
       "      <td>1.851488</td>\n",
       "      <td>-0.115561</td>\n",
       "      <td>27.474073</td>\n",
       "      <td>0.068921</td>\n",
       "      <td>1.629810</td>\n",
       "      <td>3.316009</td>\n",
       "      <td>1396.733887</td>\n",
       "      <td>3.400850</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.055541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471770</th>\n",
       "      <td>5.128566</td>\n",
       "      <td>284.982178</td>\n",
       "      <td>94.956169</td>\n",
       "      <td>77.147202</td>\n",
       "      <td>7.554247</td>\n",
       "      <td>1.254417</td>\n",
       "      <td>2.702371</td>\n",
       "      <td>22.974083</td>\n",
       "      <td>4.606533</td>\n",
       "      <td>4.899467</td>\n",
       "      <td>1.558595</td>\n",
       "      <td>14.952886</td>\n",
       "      <td>3.802980</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.058429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471970</th>\n",
       "      <td>-0.838438</td>\n",
       "      <td>340.048737</td>\n",
       "      <td>31.034472</td>\n",
       "      <td>53.579376</td>\n",
       "      <td>-0.292885</td>\n",
       "      <td>1.439927</td>\n",
       "      <td>-0.062041</td>\n",
       "      <td>74.637009</td>\n",
       "      <td>7.424857</td>\n",
       "      <td>-0.148461</td>\n",
       "      <td>43.309162</td>\n",
       "      <td>68.566292</td>\n",
       "      <td>1.943407</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.058701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472012</th>\n",
       "      <td>1.715871</td>\n",
       "      <td>317.436554</td>\n",
       "      <td>28.813572</td>\n",
       "      <td>42.742043</td>\n",
       "      <td>-0.876804</td>\n",
       "      <td>1.381478</td>\n",
       "      <td>-0.605978</td>\n",
       "      <td>41.627674</td>\n",
       "      <td>5.863369</td>\n",
       "      <td>0.977718</td>\n",
       "      <td>17.094145</td>\n",
       "      <td>19.128323</td>\n",
       "      <td>0.636132</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.058686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472030</th>\n",
       "      <td>-0.972769</td>\n",
       "      <td>219.110367</td>\n",
       "      <td>47.526218</td>\n",
       "      <td>52.151524</td>\n",
       "      <td>-0.171912</td>\n",
       "      <td>-0.469537</td>\n",
       "      <td>-0.221351</td>\n",
       "      <td>118.295059</td>\n",
       "      <td>18.078671</td>\n",
       "      <td>1.262203</td>\n",
       "      <td>12.706795</td>\n",
       "      <td>19.811781</td>\n",
       "      <td>18.685183</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.056389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29702 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         110-CD3    115-CD45  139-CD45RA   142-CD19  144-CD11b   145-CD4  \\\n",
       "8      -0.072176  219.463165   73.935654  36.863819  -1.054267 -0.147575   \n",
       "12     -2.307435  204.438171   77.867607  42.641132  -0.285443 -0.372202   \n",
       "30      1.746720  284.282013   28.760956  38.499954   1.275578 -1.653929   \n",
       "45     -4.815868  234.770752   62.574379  44.692940   3.540209 -0.526092   \n",
       "73      1.310114  108.836357   48.661461  34.506725  -1.216142 -0.464221   \n",
       "...          ...         ...         ...        ...        ...       ...   \n",
       "471739 -0.383450  246.238373   50.226032  14.160948  -0.589054  1.851488   \n",
       "471770  5.128566  284.982178   94.956169  77.147202   7.554247  1.254417   \n",
       "471970 -0.838438  340.048737   31.034472  53.579376  -0.292885  1.439927   \n",
       "472012  1.715871  317.436554   28.813572  42.742043  -0.876804  1.381478   \n",
       "472030 -0.972769  219.110367   47.526218  52.151524  -0.171912 -0.469537   \n",
       "\n",
       "         146-CD8    147-CD20   148-CD34  158-CD33  160-CD123     167-CD38  \\\n",
       "8      -0.102538   32.607048  -0.249687  0.067650   6.987092    37.832825   \n",
       "12     -4.427719   17.261219  -0.488574 -3.711010  34.505669    19.478870   \n",
       "30     -0.024098   39.808941  -0.463562  0.135652  50.319153    22.642670   \n",
       "45      0.172865   40.247784   2.179591  5.230491  -0.804634    59.010201   \n",
       "73      2.820165   37.411366  -0.315401  0.303836  22.056704    23.780251   \n",
       "...          ...         ...        ...       ...        ...          ...   \n",
       "471739 -0.115561   27.474073   0.068921  1.629810   3.316009  1396.733887   \n",
       "471770  2.702371   22.974083   4.606533  4.899467   1.558595    14.952886   \n",
       "471970 -0.062041   74.637009   7.424857 -0.148461  43.309162    68.566292   \n",
       "472012 -0.605978   41.627674   5.863369  0.977718  17.094145    19.128323   \n",
       "472030 -0.221351  118.295059  18.078671  1.262203  12.706795    19.811781   \n",
       "\n",
       "         170-CD90  bcr  branch  trajectory  \n",
       "8        2.822956    0       2    0.264602  \n",
       "12       5.564790    1       1    0.057659  \n",
       "30      -0.418175    1       1    0.058571  \n",
       "45      -0.574145    1       1    0.058252  \n",
       "73       4.541167    1       1    0.058832  \n",
       "...           ...  ...     ...         ...  \n",
       "471739   3.400850    1       1    0.055541  \n",
       "471770   3.802980    1       1    0.058429  \n",
       "471970   1.943407    1       1    0.058701  \n",
       "472012   0.636132    1       1    0.058686  \n",
       "472030  18.685183    1       1    0.056389  \n",
       "\n",
       "[29702 rows x 16 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surface_df = surface_df.merge(branches, left_index=True, right_index=True, how='inner')\n",
    "surface_df = surface_df.merge(trajectories, left_index=True, right_index=True, how='inner')\n",
    "surface_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pop off last .1 as test data\n",
    "np.random.seed(0)\n",
    "surface_df_train = surface_df.sample(frac=0.8)\n",
    "\n",
    "# to recover \n",
    "surface_test = surface_df[~surface_df.index.isin(surface_df_train.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_df_train.to_csv('../data/surface_train.csv')\n",
    "surface_test.to_csv('../data/surface_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "def get_model(input_shape):\n",
    "    inputs = keras.Input(shape=(input_shape,))\n",
    "    for i, x in enumerate([10, 8, 4]):\n",
    "        if i == 0:\n",
    "            outputs = layers.Dense(x, activation='relu')(inputs)\n",
    "        else:\n",
    "            outputs = layers.Dense(x, activation='relu')(outputs)\n",
    "    outputs = layers.Dropout(0.1, name='dropout')(outputs)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(outputs)\n",
    "\n",
    "    model1 = keras.Model(inputs, outputs)\n",
    "    \n",
    "    \n",
    "    return model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# signal df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = signal_df_train.pop('bcr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 3.2299 - acc: 0.5220 - val_loss: 0.6922 - val_acc: 0.5461\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.7040 - acc: 0.5297 - val_loss: 0.6886 - val_acc: 0.5431\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.6969 - acc: 0.5303 - val_loss: 0.6884 - val_acc: 0.5423\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.6938 - acc: 0.5284 - val_loss: 0.6896 - val_acc: 0.5372\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.6927 - acc: 0.5307 - val_loss: 0.6895 - val_acc: 0.5435\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.6879 - acc: 0.5460 - val_loss: 0.6949 - val_acc: 0.5953\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.6715 - acc: 0.5921 - val_loss: 0.6363 - val_acc: 0.6479\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.6094 - acc: 0.6850 - val_loss: 0.5409 - val_acc: 0.7615\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.5383 - acc: 0.7552 - val_loss: 0.4745 - val_acc: 0.8098\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.4604 - acc: 0.8147 - val_loss: 0.4344 - val_acc: 0.8326\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.3727 - acc: 0.8598 - val_loss: 0.3309 - val_acc: 0.9011\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.3056 - acc: 0.8989 - val_loss: 0.2245 - val_acc: 0.9525\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.2694 - acc: 0.9126 - val_loss: 0.1788 - val_acc: 0.9676\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.2440 - acc: 0.9232 - val_loss: 0.1539 - val_acc: 0.9739\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.2316 - acc: 0.9271 - val_loss: 0.1399 - val_acc: 0.9739\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.2243 - acc: 0.9277 - val_loss: 0.1202 - val_acc: 0.9806\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.2283 - acc: 0.9253 - val_loss: 0.1287 - val_acc: 0.9756\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.2149 - acc: 0.9299 - val_loss: 0.1177 - val_acc: 0.9781\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.2102 - acc: 0.9312 - val_loss: 0.1110 - val_acc: 0.9802\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.2185 - acc: 0.9260 - val_loss: 0.1096 - val_acc: 0.9811\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.1925 - acc: 0.9342 - val_loss: 0.0886 - val_acc: 0.9874\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.1712 - acc: 0.9337 - val_loss: 0.1001 - val_acc: 0.9823\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.1373 - acc: 0.9623 - val_loss: 0.0862 - val_acc: 0.9832\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.1056 - acc: 0.9772 - val_loss: 0.0657 - val_acc: 0.9907\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0916 - acc: 0.9800 - val_loss: 0.0546 - val_acc: 0.9920\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0923 - acc: 0.9780 - val_loss: 0.0683 - val_acc: 0.9857\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0814 - acc: 0.9819 - val_loss: 0.0423 - val_acc: 0.9945\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0758 - acc: 0.9830 - val_loss: 0.0374 - val_acc: 0.9958\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0795 - acc: 0.9816 - val_loss: 0.0513 - val_acc: 0.9886\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.1050 - acc: 0.9754 - val_loss: 0.0627 - val_acc: 0.9874\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0697 - acc: 0.9837 - val_loss: 0.0406 - val_acc: 0.9928\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0754 - acc: 0.9831 - val_loss: 0.0586 - val_acc: 0.9861\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0790 - acc: 0.9813 - val_loss: 0.0327 - val_acc: 0.9958\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0643 - acc: 0.9852 - val_loss: 0.0316 - val_acc: 0.9958\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0644 - acc: 0.9855 - val_loss: 0.0303 - val_acc: 0.9950\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0802 - acc: 0.9818 - val_loss: 0.0395 - val_acc: 0.9916\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0639 - acc: 0.9858 - val_loss: 0.0368 - val_acc: 0.9924\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0737 - acc: 0.9834 - val_loss: 0.0583 - val_acc: 0.9840\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0667 - acc: 0.9849 - val_loss: 0.0264 - val_acc: 0.9966\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0570 - acc: 0.9877 - val_loss: 0.0255 - val_acc: 0.9971\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0584 - acc: 0.9874 - val_loss: 0.0255 - val_acc: 0.9966\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0540 - acc: 0.9885 - val_loss: 0.0364 - val_acc: 0.9920\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0767 - acc: 0.9826 - val_loss: 0.0269 - val_acc: 0.9950\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0571 - acc: 0.9875 - val_loss: 0.0244 - val_acc: 0.9966\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0630 - acc: 0.9862 - val_loss: 0.0758 - val_acc: 0.9823\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0683 - acc: 0.9848 - val_loss: 0.0252 - val_acc: 0.9966\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0586 - acc: 0.9869 - val_loss: 0.0243 - val_acc: 0.9971\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0790 - acc: 0.9819 - val_loss: 0.0717 - val_acc: 0.9836\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0735 - acc: 0.9833 - val_loss: 0.0371 - val_acc: 0.9920\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0625 - acc: 0.9862 - val_loss: 0.0394 - val_acc: 0.9912\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0539 - acc: 0.9887 - val_loss: 0.0269 - val_acc: 0.9962\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0657 - acc: 0.9862 - val_loss: 0.0276 - val_acc: 0.9958\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0631 - acc: 0.9858 - val_loss: 0.0246 - val_acc: 0.9966\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0664 - acc: 0.9854 - val_loss: 0.0265 - val_acc: 0.9950\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0604 - acc: 0.9869 - val_loss: 0.0444 - val_acc: 0.9899\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0601 - acc: 0.9869 - val_loss: 0.0237 - val_acc: 0.9966\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0877 - acc: 0.9830 - val_loss: 0.0309 - val_acc: 0.9941\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0644 - acc: 0.9857 - val_loss: 0.0389 - val_acc: 0.9912\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0670 - acc: 0.9849 - val_loss: 0.0245 - val_acc: 0.9962\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0595 - acc: 0.9873 - val_loss: 0.0259 - val_acc: 0.9962\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0540 - acc: 0.9883 - val_loss: 0.0795 - val_acc: 0.9895\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0687 - acc: 0.9846 - val_loss: 0.0315 - val_acc: 0.9950\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0545 - acc: 0.9886 - val_loss: 0.0967 - val_acc: 0.9781\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0842 - acc: 0.9803 - val_loss: 0.0421 - val_acc: 0.9907\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0597 - acc: 0.9864 - val_loss: 0.0268 - val_acc: 0.9958\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0436 - acc: 0.9899 - val_loss: 0.0277 - val_acc: 0.9966\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0510 - acc: 0.9891 - val_loss: 0.0226 - val_acc: 0.9971\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0479 - acc: 0.9904 - val_loss: 0.0217 - val_acc: 0.9971\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0358 - acc: 0.9933 - val_loss: 0.0266 - val_acc: 0.9954\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0379 - acc: 0.9928 - val_loss: 0.0211 - val_acc: 0.9971\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0418 - acc: 0.9918 - val_loss: 0.0287 - val_acc: 0.9958\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0372 - acc: 0.9928 - val_loss: 0.0388 - val_acc: 0.9958\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0399 - acc: 0.9916 - val_loss: 0.0302 - val_acc: 0.9941\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0356 - acc: 0.9931 - val_loss: 0.0359 - val_acc: 0.9962\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0331 - acc: 0.9939 - val_loss: 0.0454 - val_acc: 0.9958\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0415 - acc: 0.9918 - val_loss: 0.0390 - val_acc: 0.9941\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0480 - acc: 0.9903 - val_loss: 0.0268 - val_acc: 0.9941\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0440 - acc: 0.9910 - val_loss: 0.0304 - val_acc: 0.9950\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0457 - acc: 0.9912 - val_loss: 0.0296 - val_acc: 0.9941\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0469 - acc: 0.9899 - val_loss: 0.0210 - val_acc: 0.9966\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0500 - acc: 0.9895 - val_loss: 0.0714 - val_acc: 0.9840\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0456 - acc: 0.9903 - val_loss: 0.0379 - val_acc: 0.9941\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0439 - acc: 0.9903 - val_loss: 0.0344 - val_acc: 0.9962\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0374 - acc: 0.9924 - val_loss: 0.0225 - val_acc: 0.9966\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0315 - acc: 0.9942 - val_loss: 0.0262 - val_acc: 0.9962\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0336 - acc: 0.9943 - val_loss: 0.0272 - val_acc: 0.9941\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0391 - acc: 0.9921 - val_loss: 0.0201 - val_acc: 0.9971\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0399 - acc: 0.9920 - val_loss: 0.0300 - val_acc: 0.9937\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0457 - acc: 0.9906 - val_loss: 0.0261 - val_acc: 0.9941\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0394 - acc: 0.9916 - val_loss: 0.0192 - val_acc: 0.9971\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0299 - acc: 0.9946 - val_loss: 0.0116 - val_acc: 0.9979\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0241 - acc: 0.9951 - val_loss: 0.0161 - val_acc: 0.9941\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0245 - acc: 0.9954 - val_loss: 0.0126 - val_acc: 0.9979\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0323 - acc: 0.9935 - val_loss: 0.0185 - val_acc: 0.9971\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0305 - acc: 0.9943 - val_loss: 0.0247 - val_acc: 0.9962\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0363 - acc: 0.9925 - val_loss: 0.0256 - val_acc: 0.9966\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0352 - acc: 0.9935 - val_loss: 0.0329 - val_acc: 0.9958\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0354 - acc: 0.9931 - val_loss: 0.0234 - val_acc: 0.9962\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0382 - acc: 0.9925 - val_loss: 0.0220 - val_acc: 0.9950\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 0.0236 - acc: 0.9955 - val_loss: 0.0161 - val_acc: 0.9983\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = get_model(signal_df_train.shape[1])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"acc\"])\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "history = model.fit(signal_df_train, y,\n",
    "                    batch_size = 64,\n",
    "                    validation_split=0.1,\n",
    "                    epochs=100\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/wishbone_signal2/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../models/wishbone_signal2'"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnn.save_model(model, '../models/wishbone_signal', history=history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# surface df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = surface_df_train.pop('bcr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(surface_df_train.shape[1])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1.1170 - acc: 0.5044 - val_loss: 0.6925 - val_acc: 0.5334\n",
      "Epoch 2/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.7038 - acc: 0.5221 - val_loss: 0.6909 - val_acc: 0.5339\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.6977 - acc: 0.5221 - val_loss: 0.6910 - val_acc: 0.5334\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.6941 - acc: 0.5221 - val_loss: 0.6908 - val_acc: 0.5339\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.6861 - acc: 0.5459 - val_loss: 0.6581 - val_acc: 0.6134\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.6310 - acc: 0.6541 - val_loss: 0.6010 - val_acc: 0.6996\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.5771 - acc: 0.7204 - val_loss: 0.5525 - val_acc: 0.7486\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.5554 - acc: 0.7333 - val_loss: 0.5284 - val_acc: 0.7664\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.5402 - acc: 0.7406 - val_loss: 0.5134 - val_acc: 0.7680\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.5282 - acc: 0.7509 - val_loss: 0.4977 - val_acc: 0.7796\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.5185 - acc: 0.7584 - val_loss: 0.4894 - val_acc: 0.7875\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.5072 - acc: 0.7675 - val_loss: 0.4758 - val_acc: 0.8038\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.4988 - acc: 0.7808 - val_loss: 0.4865 - val_acc: 0.7859\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.4804 - acc: 0.7929 - val_loss: 0.4446 - val_acc: 0.8322\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.4615 - acc: 0.8135 - val_loss: 0.4215 - val_acc: 0.8490\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.4507 - acc: 0.8189 - val_loss: 0.4050 - val_acc: 0.8522\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.4443 - acc: 0.8243 - val_loss: 0.4213 - val_acc: 0.8543\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.4273 - acc: 0.8421 - val_loss: 0.3676 - val_acc: 0.8806\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.4171 - acc: 0.8469 - val_loss: 0.3964 - val_acc: 0.8538\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.4054 - acc: 0.8556 - val_loss: 0.3435 - val_acc: 0.8943\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.4053 - acc: 0.8552 - val_loss: 0.3710 - val_acc: 0.8753\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.4019 - acc: 0.8581 - val_loss: 0.4183 - val_acc: 0.8443\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.4093 - acc: 0.8551 - val_loss: 0.3724 - val_acc: 0.8680\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.4001 - acc: 0.8586 - val_loss: 0.3586 - val_acc: 0.8895\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3953 - acc: 0.8595 - val_loss: 0.3118 - val_acc: 0.9169\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3808 - acc: 0.8665 - val_loss: 0.3138 - val_acc: 0.9137\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3669 - acc: 0.8747 - val_loss: 0.3284 - val_acc: 0.8958\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3759 - acc: 0.8673 - val_loss: 0.3622 - val_acc: 0.8711\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3756 - acc: 0.8649 - val_loss: 0.3084 - val_acc: 0.8990\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3807 - acc: 0.8639 - val_loss: 0.3348 - val_acc: 0.8974\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3694 - acc: 0.8711 - val_loss: 0.2810 - val_acc: 0.9190\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3595 - acc: 0.8744 - val_loss: 0.2782 - val_acc: 0.9232\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3537 - acc: 0.8756 - val_loss: 0.2869 - val_acc: 0.9190\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3814 - acc: 0.8639 - val_loss: 0.3049 - val_acc: 0.9016\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3607 - acc: 0.8717 - val_loss: 0.2856 - val_acc: 0.9158\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3595 - acc: 0.8724 - val_loss: 0.2651 - val_acc: 0.9290\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3458 - acc: 0.8805 - val_loss: 0.2602 - val_acc: 0.9285\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3531 - acc: 0.8767 - val_loss: 0.2884 - val_acc: 0.9179\n",
      "Epoch 39/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3476 - acc: 0.8776 - val_loss: 0.2861 - val_acc: 0.9190\n",
      "Epoch 40/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3570 - acc: 0.8735 - val_loss: 0.2642 - val_acc: 0.9206\n",
      "Epoch 41/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3467 - acc: 0.8787 - val_loss: 0.2732 - val_acc: 0.9185\n",
      "Epoch 42/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3448 - acc: 0.8785 - val_loss: 0.2820 - val_acc: 0.9200\n",
      "Epoch 43/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3433 - acc: 0.8788 - val_loss: 0.2870 - val_acc: 0.9127\n",
      "Epoch 44/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3402 - acc: 0.8816 - val_loss: 0.2679 - val_acc: 0.9264\n",
      "Epoch 45/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3458 - acc: 0.8791 - val_loss: 0.2911 - val_acc: 0.9085\n",
      "Epoch 46/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3354 - acc: 0.8835 - val_loss: 0.2597 - val_acc: 0.9290\n",
      "Epoch 47/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3462 - acc: 0.8778 - val_loss: 0.2629 - val_acc: 0.9221\n",
      "Epoch 48/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3467 - acc: 0.8771 - val_loss: 0.2608 - val_acc: 0.9285\n",
      "Epoch 49/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3629 - acc: 0.8688 - val_loss: 0.2785 - val_acc: 0.9143\n",
      "Epoch 50/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3362 - acc: 0.8851 - val_loss: 0.2559 - val_acc: 0.9274\n",
      "Epoch 51/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3406 - acc: 0.8825 - val_loss: 0.2495 - val_acc: 0.9306\n",
      "Epoch 52/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3458 - acc: 0.8794 - val_loss: 0.2609 - val_acc: 0.9285\n",
      "Epoch 53/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3419 - acc: 0.8789 - val_loss: 0.3151 - val_acc: 0.8979\n",
      "Epoch 54/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3450 - acc: 0.8774 - val_loss: 0.2510 - val_acc: 0.9327\n",
      "Epoch 55/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3448 - acc: 0.8801 - val_loss: 0.2959 - val_acc: 0.9053\n",
      "Epoch 56/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3393 - acc: 0.8819 - val_loss: 0.2794 - val_acc: 0.9116\n",
      "Epoch 57/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3557 - acc: 0.8745 - val_loss: 0.2566 - val_acc: 0.9264\n",
      "Epoch 58/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3452 - acc: 0.8791 - val_loss: 0.2459 - val_acc: 0.9311\n",
      "Epoch 59/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3320 - acc: 0.8866 - val_loss: 0.2424 - val_acc: 0.9348\n",
      "Epoch 60/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3339 - acc: 0.8834 - val_loss: 0.2669 - val_acc: 0.9179\n",
      "Epoch 61/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3308 - acc: 0.8854 - val_loss: 0.2564 - val_acc: 0.9185\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3317 - acc: 0.8830 - val_loss: 0.2468 - val_acc: 0.9290\n",
      "Epoch 63/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3338 - acc: 0.8836 - val_loss: 0.2666 - val_acc: 0.9295\n",
      "Epoch 64/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3329 - acc: 0.8864 - val_loss: 0.2352 - val_acc: 0.9327\n",
      "Epoch 65/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3299 - acc: 0.8830 - val_loss: 0.2458 - val_acc: 0.9311\n",
      "Epoch 66/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3251 - acc: 0.8869 - val_loss: 0.2525 - val_acc: 0.9295\n",
      "Epoch 67/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3385 - acc: 0.8801 - val_loss: 0.2557 - val_acc: 0.9311\n",
      "Epoch 68/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3241 - acc: 0.8860 - val_loss: 0.2432 - val_acc: 0.9321\n",
      "Epoch 69/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3280 - acc: 0.8848 - val_loss: 0.2406 - val_acc: 0.9316\n",
      "Epoch 70/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3417 - acc: 0.8790 - val_loss: 0.2587 - val_acc: 0.9253\n",
      "Epoch 71/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3268 - acc: 0.8875 - val_loss: 0.2363 - val_acc: 0.9358\n",
      "Epoch 72/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3266 - acc: 0.8870 - val_loss: 0.2317 - val_acc: 0.9363\n",
      "Epoch 73/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3412 - acc: 0.8791 - val_loss: 0.2550 - val_acc: 0.9221\n",
      "Epoch 74/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3280 - acc: 0.8852 - val_loss: 0.2450 - val_acc: 0.9311\n",
      "Epoch 75/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3270 - acc: 0.8854 - val_loss: 0.2520 - val_acc: 0.9274\n",
      "Epoch 76/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3253 - acc: 0.8880 - val_loss: 0.2358 - val_acc: 0.9353\n",
      "Epoch 77/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3170 - acc: 0.8894 - val_loss: 0.2410 - val_acc: 0.9316\n",
      "Epoch 78/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3385 - acc: 0.8805 - val_loss: 0.2516 - val_acc: 0.9253\n",
      "Epoch 79/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3414 - acc: 0.8788 - val_loss: 0.3005 - val_acc: 0.8985\n",
      "Epoch 80/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3201 - acc: 0.8895 - val_loss: 0.2247 - val_acc: 0.9400\n",
      "Epoch 81/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3200 - acc: 0.8881 - val_loss: 0.2331 - val_acc: 0.9348\n",
      "Epoch 82/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3389 - acc: 0.8803 - val_loss: 0.2497 - val_acc: 0.9306\n",
      "Epoch 83/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3216 - acc: 0.8872 - val_loss: 0.2258 - val_acc: 0.9411\n",
      "Epoch 84/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3229 - acc: 0.8882 - val_loss: 0.2500 - val_acc: 0.9316\n",
      "Epoch 85/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3203 - acc: 0.8884 - val_loss: 0.2410 - val_acc: 0.9300\n",
      "Epoch 86/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3184 - acc: 0.8895 - val_loss: 0.2505 - val_acc: 0.9279\n",
      "Epoch 87/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3225 - acc: 0.8857 - val_loss: 0.2241 - val_acc: 0.9363\n",
      "Epoch 88/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3197 - acc: 0.8882 - val_loss: 0.2301 - val_acc: 0.9342\n",
      "Epoch 89/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3117 - acc: 0.8923 - val_loss: 0.2238 - val_acc: 0.9395\n",
      "Epoch 90/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3202 - acc: 0.8873 - val_loss: 0.2631 - val_acc: 0.9148\n",
      "Epoch 91/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3218 - acc: 0.8873 - val_loss: 0.2444 - val_acc: 0.9237\n",
      "Epoch 92/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3302 - acc: 0.8843 - val_loss: 0.2334 - val_acc: 0.9348\n",
      "Epoch 93/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3232 - acc: 0.8864 - val_loss: 0.2279 - val_acc: 0.9374\n",
      "Epoch 94/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3177 - acc: 0.8900 - val_loss: 0.2285 - val_acc: 0.9358\n",
      "Epoch 95/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3194 - acc: 0.8878 - val_loss: 0.2280 - val_acc: 0.9342\n",
      "Epoch 96/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3078 - acc: 0.8936 - val_loss: 0.2446 - val_acc: 0.9258\n",
      "Epoch 97/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3238 - acc: 0.8861 - val_loss: 0.2259 - val_acc: 0.9332\n",
      "Epoch 98/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3235 - acc: 0.8866 - val_loss: 0.2533 - val_acc: 0.9264\n",
      "Epoch 99/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3220 - acc: 0.8860 - val_loss: 0.2428 - val_acc: 0.9337\n",
      "Epoch 100/100\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.3228 - acc: 0.8881 - val_loss: 0.2562 - val_acc: 0.9206\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "history = model.fit(surface_df_train, y,\n",
    "                    batch_size = 64,\n",
    "                    validation_split=0.1,\n",
    "                    epochs=100\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/wishbone_surface2/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../models/wishbone_surface2'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnn.save_model(model, '../models/wishbone_naive', history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23762, 25)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>110-CD3</th>\n",
       "      <th>115-CD45</th>\n",
       "      <th>139-CD45RA</th>\n",
       "      <th>142-CD19</th>\n",
       "      <th>144-CD11b</th>\n",
       "      <th>145-CD4</th>\n",
       "      <th>146-CD8</th>\n",
       "      <th>147-CD20</th>\n",
       "      <th>148-CD34</th>\n",
       "      <th>158-CD33</th>\n",
       "      <th>160-CD123</th>\n",
       "      <th>167-CD38</th>\n",
       "      <th>170-CD90</th>\n",
       "      <th>branch</th>\n",
       "      <th>trajectory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103281</th>\n",
       "      <td>-0.481132</td>\n",
       "      <td>248.784714</td>\n",
       "      <td>143.097122</td>\n",
       "      <td>54.863110</td>\n",
       "      <td>2.753687</td>\n",
       "      <td>13.147909</td>\n",
       "      <td>-1.370186</td>\n",
       "      <td>83.163406</td>\n",
       "      <td>4.977398</td>\n",
       "      <td>11.251880</td>\n",
       "      <td>13.962069</td>\n",
       "      <td>50.657806</td>\n",
       "      <td>1.466396</td>\n",
       "      <td>2</td>\n",
       "      <td>0.262880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388857</th>\n",
       "      <td>-0.974373</td>\n",
       "      <td>126.571587</td>\n",
       "      <td>9.464400</td>\n",
       "      <td>32.153496</td>\n",
       "      <td>-0.918507</td>\n",
       "      <td>-1.728501</td>\n",
       "      <td>-0.215477</td>\n",
       "      <td>12.470786</td>\n",
       "      <td>-0.274119</td>\n",
       "      <td>-0.340547</td>\n",
       "      <td>0.277593</td>\n",
       "      <td>11.110766</td>\n",
       "      <td>14.902977</td>\n",
       "      <td>1</td>\n",
       "      <td>0.058870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306517</th>\n",
       "      <td>-0.223668</td>\n",
       "      <td>144.316330</td>\n",
       "      <td>5.137239</td>\n",
       "      <td>16.677908</td>\n",
       "      <td>1.658641</td>\n",
       "      <td>-0.267913</td>\n",
       "      <td>-0.275669</td>\n",
       "      <td>28.161079</td>\n",
       "      <td>-0.848079</td>\n",
       "      <td>18.984800</td>\n",
       "      <td>1.359186</td>\n",
       "      <td>27.343784</td>\n",
       "      <td>-0.838904</td>\n",
       "      <td>1</td>\n",
       "      <td>0.058963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108228</th>\n",
       "      <td>-0.312490</td>\n",
       "      <td>176.851624</td>\n",
       "      <td>72.389610</td>\n",
       "      <td>38.293720</td>\n",
       "      <td>-0.849039</td>\n",
       "      <td>-0.913960</td>\n",
       "      <td>-0.269339</td>\n",
       "      <td>18.042175</td>\n",
       "      <td>-0.422611</td>\n",
       "      <td>10.066899</td>\n",
       "      <td>38.154644</td>\n",
       "      <td>36.512745</td>\n",
       "      <td>7.423636</td>\n",
       "      <td>2</td>\n",
       "      <td>0.263358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166493</th>\n",
       "      <td>0.801312</td>\n",
       "      <td>239.489166</td>\n",
       "      <td>80.141556</td>\n",
       "      <td>33.297813</td>\n",
       "      <td>11.679992</td>\n",
       "      <td>2.055430</td>\n",
       "      <td>0.395223</td>\n",
       "      <td>62.516212</td>\n",
       "      <td>8.888879</td>\n",
       "      <td>5.707616</td>\n",
       "      <td>6.729420</td>\n",
       "      <td>17.707584</td>\n",
       "      <td>5.695710</td>\n",
       "      <td>1</td>\n",
       "      <td>0.053682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325423</th>\n",
       "      <td>-0.144069</td>\n",
       "      <td>147.665237</td>\n",
       "      <td>55.637787</td>\n",
       "      <td>40.626232</td>\n",
       "      <td>0.942537</td>\n",
       "      <td>-0.595052</td>\n",
       "      <td>-4.129198</td>\n",
       "      <td>35.371353</td>\n",
       "      <td>-0.093601</td>\n",
       "      <td>8.387814</td>\n",
       "      <td>19.255114</td>\n",
       "      <td>81.409691</td>\n",
       "      <td>1.647623</td>\n",
       "      <td>2</td>\n",
       "      <td>0.263485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140523</th>\n",
       "      <td>-1.651225</td>\n",
       "      <td>273.520966</td>\n",
       "      <td>211.142822</td>\n",
       "      <td>60.851681</td>\n",
       "      <td>4.012023</td>\n",
       "      <td>-0.689578</td>\n",
       "      <td>0.725354</td>\n",
       "      <td>38.287445</td>\n",
       "      <td>4.667103</td>\n",
       "      <td>13.687876</td>\n",
       "      <td>-0.515647</td>\n",
       "      <td>78.021027</td>\n",
       "      <td>0.173368</td>\n",
       "      <td>2</td>\n",
       "      <td>0.257534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128201</th>\n",
       "      <td>-0.409057</td>\n",
       "      <td>73.494614</td>\n",
       "      <td>32.576759</td>\n",
       "      <td>22.963024</td>\n",
       "      <td>-0.821542</td>\n",
       "      <td>2.512493</td>\n",
       "      <td>14.791347</td>\n",
       "      <td>29.236551</td>\n",
       "      <td>2.743870</td>\n",
       "      <td>3.239280</td>\n",
       "      <td>-0.773837</td>\n",
       "      <td>40.983822</td>\n",
       "      <td>1.686235</td>\n",
       "      <td>2</td>\n",
       "      <td>0.265642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468129</th>\n",
       "      <td>-0.056041</td>\n",
       "      <td>95.279770</td>\n",
       "      <td>56.255215</td>\n",
       "      <td>15.047943</td>\n",
       "      <td>4.218547</td>\n",
       "      <td>3.787249</td>\n",
       "      <td>-0.641857</td>\n",
       "      <td>39.146057</td>\n",
       "      <td>-0.284752</td>\n",
       "      <td>1.224908</td>\n",
       "      <td>-0.264594</td>\n",
       "      <td>19.421221</td>\n",
       "      <td>3.261183</td>\n",
       "      <td>1</td>\n",
       "      <td>0.058928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158525</th>\n",
       "      <td>-0.520575</td>\n",
       "      <td>332.639191</td>\n",
       "      <td>27.769833</td>\n",
       "      <td>44.099262</td>\n",
       "      <td>-0.740818</td>\n",
       "      <td>4.609190</td>\n",
       "      <td>-0.494869</td>\n",
       "      <td>41.902901</td>\n",
       "      <td>11.107522</td>\n",
       "      <td>-0.777705</td>\n",
       "      <td>24.929420</td>\n",
       "      <td>53.432056</td>\n",
       "      <td>-0.899824</td>\n",
       "      <td>1</td>\n",
       "      <td>0.058812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19010 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         110-CD3    115-CD45  139-CD45RA   142-CD19  144-CD11b    145-CD4  \\\n",
       "103281 -0.481132  248.784714  143.097122  54.863110   2.753687  13.147909   \n",
       "388857 -0.974373  126.571587    9.464400  32.153496  -0.918507  -1.728501   \n",
       "306517 -0.223668  144.316330    5.137239  16.677908   1.658641  -0.267913   \n",
       "108228 -0.312490  176.851624   72.389610  38.293720  -0.849039  -0.913960   \n",
       "166493  0.801312  239.489166   80.141556  33.297813  11.679992   2.055430   \n",
       "...          ...         ...         ...        ...        ...        ...   \n",
       "325423 -0.144069  147.665237   55.637787  40.626232   0.942537  -0.595052   \n",
       "140523 -1.651225  273.520966  211.142822  60.851681   4.012023  -0.689578   \n",
       "128201 -0.409057   73.494614   32.576759  22.963024  -0.821542   2.512493   \n",
       "468129 -0.056041   95.279770   56.255215  15.047943   4.218547   3.787249   \n",
       "158525 -0.520575  332.639191   27.769833  44.099262  -0.740818   4.609190   \n",
       "\n",
       "          146-CD8   147-CD20   148-CD34   158-CD33  160-CD123   167-CD38  \\\n",
       "103281  -1.370186  83.163406   4.977398  11.251880  13.962069  50.657806   \n",
       "388857  -0.215477  12.470786  -0.274119  -0.340547   0.277593  11.110766   \n",
       "306517  -0.275669  28.161079  -0.848079  18.984800   1.359186  27.343784   \n",
       "108228  -0.269339  18.042175  -0.422611  10.066899  38.154644  36.512745   \n",
       "166493   0.395223  62.516212   8.888879   5.707616   6.729420  17.707584   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "325423  -4.129198  35.371353  -0.093601   8.387814  19.255114  81.409691   \n",
       "140523   0.725354  38.287445   4.667103  13.687876  -0.515647  78.021027   \n",
       "128201  14.791347  29.236551   2.743870   3.239280  -0.773837  40.983822   \n",
       "468129  -0.641857  39.146057  -0.284752   1.224908  -0.264594  19.421221   \n",
       "158525  -0.494869  41.902901  11.107522  -0.777705  24.929420  53.432056   \n",
       "\n",
       "         170-CD90  branch  trajectory  \n",
       "103281   1.466396       2    0.262880  \n",
       "388857  14.902977       1    0.058870  \n",
       "306517  -0.838904       1    0.058963  \n",
       "108228   7.423636       2    0.263358  \n",
       "166493   5.695710       1    0.053682  \n",
       "...           ...     ...         ...  \n",
       "325423   1.647623       2    0.263485  \n",
       "140523   0.173368       2    0.257534  \n",
       "128201   1.686235       2    0.265642  \n",
       "468129   3.261183       1    0.058928  \n",
       "158525  -0.899824       1    0.058812  \n",
       "\n",
       "[19010 rows x 15 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surface_df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
